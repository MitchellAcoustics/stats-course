---
title: "Data Science Lifecycle"
date: "10/11/2022"
---

Data science uses a combination of methods and principles from statistics and computer science to work with and draw insights from data. Learning both computing and statistics together makes us better data scientists and statisticians.

To help you keep track of the big picture, we have organized topics around a work‐flow that we call the data science lifecycle. In these notes, we introduce this lifecycle, and provides a map that shows you how what you have learned so far in this course fits into the lifecycle and provides a guide for the remainder of the semester.

Figure shows the data science lifecycle. We have split it into four stages: asking a question, obtaining data, understanding the data, and understanding the world. We have made these stages very broad on purpose. In our experience, the mechanics of the lifecycle change frequently. Computer scientists and statisticians continue to build new software packages and programming languages for working with data, and they develop new methodologies that are more specialized. Despite these changes, we have found that almost every data project follows the four steps in our lifecycle. 


### Ask a Question. 

Asking good questions lies at the heart of data science, and recognizing different kinds of questions guides us in our analyses. For example, “How have house prices changed over time?” is very different from “How will this new policy affect house prices?” In this book, we focus on four broad categories of questions: descriptive, exploratory, inferential, and predictive. Narrowing down a broad question into one that can be answered with data is a key element of this first stage in the lifecycle. It can involve consulting the people participating in a study, figuring out how to measure something, and designing data collection protocols. A clear and focused research question helps us determine the data we need, the patterns to look for, and how to interpret results. These considerations help us plan the data collection phase of the lifecycle.

### Obtain Data. 

When data are expensive and hard to gather and when our aim is to generalize from the data to the world, then we aim to define precise protocols for collecting the data needed to answer the question. Other times, data are cheap and easily accessed. This is especially true for online data sources. For example, Twitter lets people quickly download millions of data points 1. When data are plentiful, we can start an analysis by obtaining data, exploring it, and then honing the research question. In both situations, most data have missing values, weird values, or other anomalies that we need to account for. When we obtain data, we need to check its quality. And, typically, we must manipulate the data before we can analyze it more formally. We may need to modify the structure and clean and transform data values to prepare for analysis.

### Understand the Data. 

After obtaining and preparing data, we want to carefully examine them, and exploratory data analysis is key. In our explorations we make plots to uncover interesting patterns and summarize the data visually. We also continue to look for problems with the data. As we search for patterns and trends, we use summary statistics and build statistical models, like linear and logistic regression. In our experience, this stage of the lifecycle is highly iterative. Understanding the data can lead us back to any of the earlier stages in the data science lifecycle. We may find that we need to modify or redo our data cleaning and manipulation, acquire more data to supplement our analysis, or refine our research question given the limitations of the data. The descriptive and exploratory analyses that we carry out in this stage may adequately answer our question, or, we may need to go on to the next stage in order to make generalizations beyond our data.

### Understand the World. 

Often our goals are purely exploratory, and the analysis ends at the Understand the Data stage of the lifecycle. At other times, we aim to quantify how well the trends we find generalize beyond our data. We may want to use a model that we have fitted to our data to make inferences about the world or give predictions for future observations. To draw inferences from a sample to a population, we use statistical techniques like A/B testing and confidence intervals. And to make predictions for future observations, we create other kinds of interval estimates and use test/train splits of the data.

## Questions and Data Scope

As data scientists we use data to answer questions, and the quality of the data collec‐ tion process can significantly impact the validity and accuracy of the data, the strength of the conclusions we draw from an analysis, and the decisions we make. In this chapter, we describe a general approach for understanding data collection and evaluating the usefulness of the data in addressing the question of interest. Ideally, we aim for data to be representative of the phenomenon that we are studying, whether that phenomenon is a population characteristic, a physical model, or some type of social behavior. Typically, our data do not contain complete information (the scope is restricted in some way), yet we want to use the data to accurately describe a popula‐ tion, estimate a scientific quantity, infer the form of a relationship between features, or predict future outcomes. In all of these situations, if our data are not representative of the object of our study, then our conclusions can be limited, possibly misleading, or even wrong.

## Target Population, Access Frame, Sample

An important initial step in the data life cycle is to express the question of interest in the context of the subject area and consider the connection between the question and the data collected to answer that question. It’s good practice to do this before even thinking about the analysis or modeling steps because it may uncover a disconnect where the question of interest cannot be directly addressed with these data. As part of making the connection between the data collection process and the topic of investigation, we identify the population, the means of accessing the population, instruments of measurement, and additional protocols used in the collection process. These concepts help us understand the scope of the data, whether we aim to gain knowledge about a population, scientific quantity, physical model, social behavior, etc.


The target population consists of the collection of elements that you ultimately intend to describe and draw conclusions about. By element we mean those individuals that make up our population. The element may be a person in a group of people, a voter in an election, a tweet from a collection of tweets, or a county in a state. We some‐ times call an element a unit or an atom.

The access frame is the collection of elements that are accessible to you for measure‐ ment and observation. These are the units by which you can access the target popula‐ tion. Ideally, the frame and population are perfectly aligned; meaning they consist of the exact same elements. However, the units in an access frame may be only a subset of the target population; additionally, the frame may include units that don’t belong to the population. For example, to find out how a voter intends to vote in an election, you might call people by phone. Someone you call, may not be a voter so they are in your frame but not in the population. On the other hand, a voter who never answers a call from an unknown number can’t be reached so they are in the population but not in your frame.

The sample is the subset of units taken from the access frame to measure, observe, and analyze. The sample gives you the data to analyze to make predictions or general‐ izations about the population of interest.

The contents of the access frame, in comparison to the target population, and the method used to select units from the frame to be in the sample are important factors in determining whether or not the data can be considered representative of the target population. If the access frame is not representative of the target population, then the data from the sample is most likely not representative either. And, if the units are sampled in a biased manner, problems with representativeness also arise.

You will also want to consider time and place in the data scope. For example, the effectiveness of a drug trial tested in one part of the world where a disease is raging might not compare as favorably with a trial in a different part of the world where background infection rates are lower (see Chapter 3). Additionally, data collected for the purpose of studying changes over time, like with the monthly measurements of CO2 in the atmosphere (see Chapter 9) and the weekly reporting of Google searches for predicting flu trends have a temporal structure that we need to be mindful of as we examine the data. At other times, there might be spatial patterns in the data. For example, the environmental heath data, described later in this section, are reported for each census tract in the State of California, and we might, say, make maps to look for spatial correlations.

And, if you didn’t collect the data, you will want to consider who did and for what purpose. This is especially relevant now since more data is passively collected instead of collected with a specific goal in mind. Taking a hard look at found data and asking yourself whether and how these data might be used to address your question can save you from making a fruitless analysis or drawing inappropriate conclusions.

For each of the following examples, we begin with a general question, narrow it to one that can be answered with data, and in doing so, we identify the target popula‐ tion, access frame, and sample. These concepts are represented by circles in a diagram of data scope, and the configuration of their overlap helps reveal key aspects the scope. Also in each example, we describe relevant temporal and spatial features to the data scope.

## Instruments and Protocols

When we consider the scope of the data, we also consider the instrument being used to take the measurements and the procedure for taking measurements, which we call the protocol. For a survey, the instrument is typically a questionnaire that an individual in the sample answers. The protocol for a survey includes how the sample is chosen, how nonrespondents are followed up, interviewer training, protections for confidentiality, etc.

Good instruments and protocols are important to all kinds of data collection. If we want to measure a natural phenomenon, such as the speed of light, we need to quan‐ tify the accuracy of the instrument. The protocol for calibrating the instrument and taking measurements is vital to obtaining accurate measurements. Instruments can go out of alignment and measurements can drift over time leading to poor, highly inaccurate measurements.

Protocols are also critical in experiments. Ideally, any factor that can influence the outcome of the experiment is controlled. For example, temperature, time of day, con‐ fidentiality of a medical record, and even the order of taking measurements need to be consistent to rule out potential effects from these factors getting in the way.

With digital traces, the algorithms used to support online activity are dynamic and continually re-engineered. For example, Google’s search algorithms are continually tweaked to improve user service and advertising revenue. Changes to the search algo‐ rithms can impact the data generated from the searches, which in turn impact sys‐ tems built from these data, such as the Google Flu Trend tracking system. This changing environment can make it untenable to maintain data collection protocols and difficult to replicate findings.

Many data science projects involve linking data together from multiple sources. Each source should be examined through this data-scope construct and any difference across sources considered. Additionally, matching algorithms used to combine data from multiple sources need to be clearly understood so that populations and frames from the sources can be compared.

Measurements from an instrument taken to study a natural phenomenon can also be cast in the scope-diagram of a target, access frame, and sample. This approach is helpful in understanding their accuracy.

## Measuring Natural Phenomenon

The scope-diagram introduced for observing a target population can be extended to the situation where we want to measure a quantity such as the count of particles in the air, the age of a fossil, the speed of light, etc. In these cases we consider the quan‐ tity we want to measure as an unknown value. (This unknown value referred is often referred to as a parameter.) In our diagram, we shrink the target to a point that repre‐ sents this unknown. The instrument’s accuracy acts as the frame, and the sample con‐ sists of the measurements taken by the instrument within the frame. You might think
of the frame as a dart board, where the instrument is the person throwing the darts. If they are reasonably good, the darts land within the circle, scattered around the bulls‐ eye. The scatter of darts correspond to the measurements taken by the instrument. The target point is not seen by the dart thrower, but ideally it coincides with the bulls‐ eye.

To illustrate the concepts of measurement error and the connection to sampling error, we examine the problem of calibrating air quality sensors.

How accurate is my air quality monitor? Across the US, sensors to measure air pollu‐ tion are widely used by individuals, community groups, and state and local air monitoring agencies (Owyang 2020). For example, on two days in September, 2020, approximately 600,000 Californians and 500,000 Oregonians viewed PurpleAir’s map as fire spread through their states and evacuations were planned. PurpleAir creates air quality maps from crowd-sourced data that streams in from their sensors.

We can think of the data scope as follows: at any location and point in time, there is a true particle composition in the air surrounding the sensor, this is our target. Our instrument, the sensor, takes many measurements, in some cases a reading every sec‐ ond. These form a sample contained in the access frame, the dart board. If the instrument is working properly, the measurements are centered around the bullseye, and the target coincides with the bullseye. Researchers have found that low humidity can distort the readings so that they are too high.

## Accuracy

In a census, the access frame matches the population, and the sample captures the entire population. In this situation, if we administer a well-designed questionnaire, then we have complete and accurate knowledge of the population and the scope is complete. Similarly in measuring air quality, if our instrument has perfect accuracy and is properly used, then we can measure the exact value of the air quality. These situations are rare, if not impossible. In most settings, we need to quantify the accu‐ racy of our measurements in order to generalize our findings to the unobserved. For example, we often use the sample to estimate an average value for a population, infer the value of a scientific unknown from measurements, or predict the behavior of a new individual. In each of these settings, we also want a quantifiable degree of accu‐ racy. We want to know how close our estimates, inferences, and predictions are to the truth.

The analogy of darts thrown at a dart board that was introduced earlier can be useful in understanding accuracy. We divide accuracy into two basic parts: bias and variance (also known as precision). Our goal is for the darts to hit the bullseye on the dart board and for the bullseye to line up with the unseen target. The spray of the darts on the board represents the variance in our measurements, and the gap from the bullseye to the unknown value that we are targeting represents the bias. 

Representative data puts us in the top row of the diagram, where there is low bias, meaning that the bullseye and the unseen target are in alignment. Ideally our instru‐ ments and protocols put us in the upper left part of the diagram, where the variance is also low. The pattern of points in the bottom row systematically miss the targeted value. Taking larger samples will not correct this bias.
Types of Bias
Bias comes in many forms. We describe some classic types here and connect them to our target-access-sample framework.

+ Coverage bias occurs when the access frame does not include everyone in the tar‐ get population. For example, a survey based on cell-phone calls cannot reach those with only a landline or no phone. In this situation, those who cannot be reached may differ in important ways from those in the access frame.

+ Selection bias arises when the mechanism used to choose units for the sample tends to select certain units more often than they should. As an example, a convenience sample chooses the units most easily available. Problems can arise when those who are easy to reach differ in important ways from those harder to reach. Another example of selection bias can happen with observational studies and experiments. These studies often rely on volunteers (people who choose to par‐ ticipate), and this self-selection has the potential for bias, if the volunteers differ from the target population in important ways.

+ Non-response bias comes in two forms: unit and item. Unit non-response hap‐ pens when someone selected for a sample is unwilling to participate, and item non-response occurs when, say, someone in the sample refuses to answer a par‐ ticular survey question. Non-response can lead to bias if those who choose not to participate or to not answer a particular question are systematically different from those who respond.

+ Measurement bias happens when an instrument systematically misses the target in one direction. For example, low humidity can systematically give us incor‐ rectly high measurements of air pollution. In addition, measurement devices can become unstable and drift over time and so produce systematic errors. In sur‐ veys, measurement bias can arise when questions are confusingly worded or leading, or when respondents may not be comfortable answering honestly.

Each of these types of bias can lead to situations where the data are not centered on the unknown targeted value. Often we cannot assess the potential magnitude of the bias, since little to no information is available on those who are outside of the access frame, less likely to be selected for the sample, or disinclined to respond. Protocols are key to reducing these sources of bias. Chance mechanisms to select a sample from the frame or to assign units to experimental conditions can eliminate selection bias. A non-response follow-up protocol to encourage participation can reduce non- response bias. A pilot survey can improve question wording and so reduce measurement bias. Procedures to calibrate instruments and protocols to take measurements in, say, random order can reduce measurement bias.

Bias does not need to be avoided under all circumstances. If an instrument is highly precise (low variance) and has a small bias, then that instrument might be preferable to another with higher variance and no bias. As an example, biased studies are poten‐ tially useful to pilot a survey instrument or to capture useful information for the design of a larger study. Many times we can at best recruit volunteers for a study. Given this limitation, it can still be useful to enroll these volunteers in the study and use random assignment to split them into treatment groups. That’s the idea behind randomized controlled experiments.

Whether or not bias is present, data typically also exhibit variation. Variation can be introduced purposely by using a chance mechanism to select a sample, and it can occur naturally through an instrument’s precision. In the next section, we identify three common sources of variation


## Types of Variation

Variation that results from a chance mechanism has the advantage of being quantifiable.

+ Sampling variation results from using chance to take a sample. We can in principle compute the chance a particular sample is selected.

+ Assignment variation of units to treatment groups in a controlled experiment produces variation. If we split the units up differently, then we can get different results from the experiment. This randomness allows us to compute the chance of a particular group assignment.

+ Measurement error for instruments result from the measurement process; if the instrument has no drift and a reliable distribution of errors, then when we take multiple measurements on the same object, we get variations in measurements that are centered on the truth.

The Box Model is a simple abstraction that can be helpful for understanding variation. This model examines a container (a box) full of identical tickets that have been labeled, and we use the simple action of drawing tickets from the box to reason about sampling schemes, randomized controlled experiments, and measurement error. For each of these types of variation, the urn model helps us estimate the size of the variation using either probability or simulation. The example of selecting Wikipedia contributors to receive an informal award provides two examples of the urn model.

## Summary

No matter the kind of data you are working with, before diving into cleaning, explo‐ration, and analysis, take a moment to look into the data’s source. If you didn’t collect the data, ask yourself:

+ Who collected the data?
+ Why were the data collected?

Answers to these questions can help determine whether these found data can be used to address the question of interest to you.

Consider the scope of the data. Questions about the temporal and spatial aspects of data collection can provide valuable insights:

+ When were the data collected?
+ Where were the data collected?

Answers to these questions help you determine whether your findings are relevant to the situation that interests you, or whether your situation that may not be comparable to this other place and time.

Core to the notion of scope are answers to the following questions:

+ What is the target population (or unknown parameter value)?
+ How was the target accessed?
+ What methods were used to select samples/take measurements?
+ What instruments were used and how were they calibrated?

Answering as many of these questions as possible can give you valuable insights as to how much trust you can place in your findings and how far you can generalize your findings.

These notes have provided you with a terminology and framework for thinking about and answering these questions. The chapter has also outlined ways to identify possible sources of bias and variance that can impact the accuracy of your findings. To help you reason about bias and variance, we have introduced the following diagrams and notions:

+ Scope diagram to indicate the overlap between target population, access frame, and sample;
+ Dart board to describe an instrument’s bias and variance; and
+ Box model for situations when a chance mechanism has been used to select a sample from an access frame, divide a group into experimental treatment groups, or take measurements from a well calibrated instrument.

These diagrams and models attempt to boil down key concepts to understanding how to identify limitations and judge the usefulness of your data in answering your question. 

We will continue the development of the box model to more formally quantify accuracy and design simulation studies.
