---
title: "Defining Causality"
subtitle: "Conditional counterfactuals and two strategies for constructing causal claims"
image: images/causal.png
format:
  html:
    code-fold: true
    code-link: true
    code-summary: "."
  pdf: default
execute: 
  warning: false
  message: false
---
:::{style="text-align: center"}
## Welcome to Unit III: Causality
:::

At the beginning of this course, we considered four different claims associated with the following news article[^nyt]. 

1. The Consumer Price Index rose 8.3% in April.
2. The global consumer price index rose in April.
3. The Consumer Price Index rose 8.3% because of the war in Ukraine.
4. The Consumer Price Index will likely rise throughout the summer.

![](images/nyt-inflation.png){#fig-inflation fig-align=center width="600px"}

Each one of these four claims illustrates a different type of claim made using data. As a brief recap of where we are in this course, let's take them each in turn.

> 1. The Consumer Price Index rose 8.3% in April.

This is a claim concerning the nature of the data that is on hand, a *descriptive* claim. While these seem like the most straightforward type of claim, don't underestimate their utility or the challenges involved in crafting them. Deciding which measure is most appropriate is tricky work and the process of wrangling the data takes careful thought and time.



<!-- While there are a host of complex machine learning models that we could use to make our predictions, we could also consider a simple linear model using the method of least squares. The best predictive model will have enough complexity to capture the structure in the data but not so much flexibility that it overfits. One of the most powerful tools for choosing between different predictive models is to compare their test set error using crossvalidation. -->

> 2. The global consumer price index rose in April.

This claim looks deceptively like the first but there is one important difference. The first claim concerns the CPI, which is calculated using data from the US. This second claim is about the broader global population of which the US data is a subset. In other words, this is a *generalization* from a sample to a population.

For a generalization to be sound, we must take several considerations into account. First off: is the sample representative of the population or is it biased in some way? Secondly: what sources of variability are present? When working with a sample that originated from a chance method, it's important to consider the degree to which sampling variability might be able to explain the structure you see in the data. Our primary tools in this area are the confidence interval, to assess the uncertainty in a statistic, and the hypothesis test, to assess whether a particular statistic is consistent with an assertion about the state of the population parameters.

> 3. The Consumer Price Index will likely rise throughout the summer. 

This is a *prediction*, a claim that uses the structure of the data at hand to predict the value of observations about which we have only partial information. In midsummer, we know the date will be July 15th, that's the x-coordinate. But what will the y-coordinate be, the Consumer Price Index?  Now we recognize this as a regression problem. 

> 4. The Consumer Price Index rose 8.3% because of the war in Ukraine.

This bring us to the final claim, which is one concerning *causation*. The claim asserts that the structure in the data (the rise in the CPI) can be attributed to specific cause (the war in Ukraine). Causal claims are often the most challenging claims to craft but they are also some of the most useful. Uncovering causes and effects is at the heart of many sciences from Economics to Biomedicine. They also help guide decision making for individuals (is it worth my time to study for the final?) as well as for organizations (will Twitter's new option to pay for verification result in a net increase in revenue for the company?).

For the remainder of Stat 20, we lay the foundation for causation, first by defining it precisely, then identifying a few of the most powerful strategies for inferring it from data.

![Four types of claims made with data covered in this class.](images/claims-only.png){#fig-claims width="500px"}

[^nyt]: Smialek, Jeanna (2022, May 11). Consumer Prices are Still Climbing Rapidly. *The New York Times*. <https://www.nytimes.com/2022/05/11/business/economy/april-2022-cpi.html>

## Causality Defined

<!-- Alternate intro: do you think smoking causes cancer? Why? Don't we need an experiment to infer causation? --> 

What exactly does it mean to say that "A causes B"?

We speak of causes and effects all the time, even though the language we use varies widely. "I took an aspirin and my headache got better" implies that taking the aspirin is what caused your headache to get better. "She was able to find a good job because she graduated from Berkeley" is more direct: graduating from Berkeley was the cause of her being able to find a good job.

Identifying a causal statement is one thing, but we're still left the conundrum: what definition can we use to be precise about the meaning of a causal statement?

Let's see what your intuition tells you about what is a cause and what is not a cause. Which causes do you identify in the following scenario[^marksmen]?

[^marksmen]: This example appears in *The Book of Why* (2018) by Pearl and Mackenzie, as do subsequent historical quotations from Thucydides and Hume.

> Suppose that a prisoner is about to be executed by a firing squad. A certain chain of events must occur for this to happen. First, the judge orders the execution. The order goes to a captain, who signals the two soldiers of the firing squad (soldier 1 and soldier 2) to fire. They are obedient and expert marksmen, so they only fire on command, and if either one of them shoots, the prisoner dies.
>
>Who caused the death of the prisoner?
>
>A. The judge  
>B. The captain  
>C. Soldier 1  
>D. Soldier 2

As you ponder where to draw the line to determine which of the these four people are the cause of the death of the prisoner, you are working out your own internal definition of causation. Keep your answers on hand; we will discuss this example in class. For now, though, let's introduce the most widely used definitions of cause and effect.

### The Conditional Counterfactual

One of the earliest articulations of what it means to be a cause can be found in the writing of Thucydides, the ancient Greek historian. It comes at the end of a passage where he describes a village called Orobiae, which experienced an earthquake followed by a tsunami.

> About the same time that these earthquakes were so common, the sea at Orobiae, in Euboea, retiring from the then line of coast, returned in a huge wave and invaed part o the town, and retreated leaving some of it still under water; so that what was once land is now sea...
>
> The cause, in my opinion of this phenomenon must be sought in the earthquake. At the point where its shock has been the most violent, the sea is driven back, and suddenly recoiling with redoubled force, causes the inundation.
>
> Without the earthquake, I do not see how such an accident could happen.

In the final line, Thucydides makes a leap: he imagines a world where the earthquake didn't happen, and can't imagine the tsunami happening. This, for him, is what makes the earthquake the cause of the tsunami. This form of reasoning about causation was summarized centuries later by the Scottish philosopher David Hume, who characterized a cause as a scenario in which  "If the first object had not been, the second never had existed."

Both of these definitions rely upon imagining a world that was different from the one that was observed, a notion in logic called a counterfactual.

**Counterfactual**
:    Relating to or expressing what has not happened or is not the case.

This notion is the core component of the most widely used definition of a cause, the conditional counterfactual defintion.

**Cause**
:    We say "A causes B" if, in a world where A didn't happen, B no longer happens.

Using this definition of causality, let's revisit two examples from above.

1. Consider the claim, "I took an aspirin and my headache got better".

   Using the conditional counterfactual definition, what would you need to know to determine if the aspirin caused the headache to improve?

<details>

<summary>Check your answer</summary>

   You would need to know that if they hadn't taken an aspirin, that their headache didn't get better.

</details>

2. Consider the claim, "She was able to find a good job because she graduated from Berkeley".

   Using the conditional counterfactual definition, what would you need to know to determine if graduating from Berkeley caused her to find a good job?

<details>

<summary>Check your answer</summary>

   You would need to know that if she hadn't graduated from Berkeley, that she wasn't able to find a good job.

</details>

In both of these examples, reasoning about the meaning of causation requires identifying the counterfactual. The language of counterfactuals can be awkward and that awkwardness points to the primary challenge of identifying a causal claim.

### The Challenge of Causation

> Counterfactuals have a partcularly problematic relationship wth data because data are, by definition, facts.
> - Judea Pearl

The conditional counterfactual definition of causation is sound in an abstract sense, but it is challenging when you start to think through what sort of data you could collect as evidence of causation. In the second example, we have data on the fact that she found a good job and that she graduated from Berkeley, but the counterfactual - that remains purely hypothetical. In fact, the word counterfactual means counter-to-fact, and "fact" is the meaning of the Latin word "datum" (a single piece of data). That is to say, for airtight evidence of a cause-and-effect, you must observe some data and then something that is somehow also the contrary to what you observed.

In an idealized world, to demonstrate that graduating from Cal was the cause of getting a good job, you would observe this data frame[^evelyn].

[^evelyn]: An a historical aside, [Evelyn Fix](https://en.wikipedia.org/wiki/Evelyn_Fix) is the name of a past professor of statistics at UC Berkeley and the co-inventor of the k-nearest neighbors algorithm.

```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(kableExtra)
options(kableExtra.html.bsTable = TRUE)

tab <- tibble(`Student` = c("Evelyn Fix", "Evelyn Fix"),
              `Cal Grad` = c("yes", "no"),
              `Good Job` = c("yes", "no"))
```

::: {.content-hidden unless-format="html"}
```{r}
#| echo: false
#| message: false
#| warning: false
tab %>%
    kbl(escape = FALSE) %>%
    kable_styling(bootstrap_options = c("hover", "striped"))
```
:::

::: {.content-hidden unless-format="pdf"}
```{r}
#| echo: false
#| message: false
#| warning: false
tab %>%
    kable(format = "latex")
```
:::

In this idealized data frame, the two rows are both observations of the same person, so they have the same values of every possible variable: work experience, GPA, letters of recommendation, etc. The primary difference is one of them graduated from Cal and the other (from the counterfactual world) did not. Because they differed on their outcome variables (getting a good job), this would serve as rock solid proof that graduating from Cal caused Evelyn to get a good job.

The challenge of using data to make causal clams is that we only ever get to observe one of the two rows above. Said another way, there are two *potential outcomes* for this scenario. One was observed (the job outcome after going to Cal) and the other was not (the job outcome without going to Cal).

If you've ever used a GPS navigation app, you're already accustomed to thinking in terms of potential outcomes. Here is the guidance Google Maps gives me to travel from Pimentel Hall at Cal to downtown Oakland by car.

![](images/the-route-not-taken.png){fig-align="center" width="300"}

Each one of the three paths is a potential route I could take and each of those times are the app's predictions for what the potential outcomes will be. Importantly, though, these are just predictions, not data. To collect data, I have to select one of these routes to drive, then I could record data on the time it took me. If I choose the blue path and it ends up taking me 16 minutes, I'll never know for sure that it was my choice of the blue route that led to this apparently short drive time. To know that, I'd have to rewind the clock and, in a different world, decide to take one of the gray routes and observe a drive time that is more than 16 minutes.

While our definition of causation prevents us from ever making completely airtight conclusions about cause and effect in scenarios like these, over the years scientists and statisticians have crafted many clever strategies for working around these constraints to build compelling causal claims.

## From individual-level claims to group-level claims


Our inability to observe both counterfactuals makes it hard to make reliable
claims about causal effects for an individual.  However, it can sometimes be easier
to make a claim about the typical causal effect among a group of individuals.
The distinction between individual and group level causation is demonstrated in following two statements.

1. Evelyn got a good job because she graduated from Cal.
2. Graduating from Cal helps people get a good job.

The first is a strong statement about a single individual, Evelyn. The second is a much more general statement that compares people who have have graduated from Cal with a counterfactual group who has not.

Group-level causation is the focus of many sciences, which aim to make general claims about the causal mechanisms of the world. The goal is to estimate the         average treatment effect.

**Average Treatment Effect**
:    A population parameter that captures the effect of being administered a particular treatment, averaged over each group. Most often estimated by a difference in sample means or a difference in sample proportions.

In statement two above, a natural estimate for the average treatment effect would be the difference between the proportion of Cal graduates who got a good job and the proportion of non-Cal graduates who got a good job. That can be visualized in a simple example of three students who graduated from Cal and three who did not. The difference in the proportion with a good job is $2/3 - 1/3 = 1/3$.

::: {layout="[-1,5,1,3,-1]" layout-valign="center"}

```{r}
#| echo: false

library(tidyverse)
library(gt)

df <- tibble(Name = c("Evelyn", "Grace", "Juan", "Alex", "Monica", "Sriya"),
                `Cal Grad`= c(TRUE, TRUE, TRUE, FALSE, FALSE, FALSE),
                 `Good Job` = c(TRUE, FALSE, TRUE, FALSE, FALSE, TRUE))

df %>%
  gt() %>%
  cols_width(
    vars(Name) ~ px(70),
    vars(`Cal Grad`) ~ px(90),
    vars(`Good Job`) ~ px(90),
  ) %>%
  tab_options(data_row.padding = px(4)) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightgoldenrodyellow")
    ),
    locations = cells_body(
      columns = everything(),
      rows = `Cal Grad` == TRUE
    )
  )  %>%
  tab_style(
    style = list(
      cell_fill(color = "lightcyan")
    ),
    locations = cells_body(
      columns = everything(),
      rows = `Cal Grad` == FALSE
    )
  )
```

{{< fa arrow-right size=2x >}}

```{r}
#| echo: false

df %>%
  group_by(`Cal Grad`) %>%
  summarize(`P(Good Job)` = round(mean(`Good Job`), 2)) %>%
  slice(2, 1) %>%
  gt() %>%
  cols_width(
    vars(`Cal Grad`) ~ px(90),
    vars(`P(Good Job)`) ~ px(110),
  ) %>%
  tab_options(data_row.padding = px(4)) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightgoldenrodyellow")
    ),
    locations = cells_body(
      columns = everything(),
      rows = `Cal Grad` == TRUE
    )
  )  %>%
  tab_style(
    style = list(
      cell_fill(color = "lightcyan")
    ),
    locations = cells_body(
      columns = everything(),
      rows = `Cal Grad` == FALSE
    )
  )
```

:::

By broadening our focus to the average treatment effect across groups, we're able to bring to bear one most convincing forms of evidence of a causal link: data from experiments.

## Principles of Experimental Design

An experiment is generally characterized as being a setting where the researcher actively assigns subjects or units to one particular condition or another. The most potent design of an experiment to determine whether one variable, the *treatment*, affects the outcome at the group level is the aptly named *Randomized Controlled Trial (RCT)*. 

As a running example, consider an immediately relevant question: would reading these notes as a webpage (and maybe copying and pasting code cells into RStudio) lead to a deeper understanding and a correspondingly better score on the final exam? Let's run through each term one-by-one to think through how to design an RCT and effectively answers this question.

### Control

**Control**
:    (noun) A second condition to which a subject or unit could be assigned that draws a contrast with the treatment condition.

:    (verb) Actions taken to eliminate other possible causal factors and ensure that the only difference between the treatment and control group is the factor of interest.

When designing an RCT, an essential decision is the nature of your control group. Our research question is: will reading these notes as a webpage result in a deeper understanding? Deeper . . . than what? Deeper than if you didn't read the notes at all? Deeper than if you read them aloud?

If we're most interested in the difference between reading the notes as a webpage and reading them as a pdf, we could declare those who read the pdf part of the control group and those who read the pdf as part of the treatment group[^control]. Small changes to the control group can make an important difference in the precise question that you'll be answering.

We can visualize the distinction between the two groups in a small example with three people in the control group (pdf) and three people in the treatment group (website).

```{r}
#| echo: false
library(gt)
df <- data.frame(name = c("Evelyn", "Grace", "Juan", "Alex", "Monica", "Sriya"),
                 group = c("pdf", "pdf", "pdf", "website", "website", "website"),
                 understanding = c("deep", "shallow", "deep", "deep", "shallow", "shallow"))
df %>%
  gt() %>%
  cols_width(
    vars(name) ~ px(70),
    vars(group) ~ px(70),
    vars(understanding) ~ px(110),
  ) %>%
  tab_options(data_row.padding = px(4)) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightgoldenrodyellow")
    ),
    locations = cells_body(
      columns = everything(),
      rows = group == "pdf"
    )
  )  %>%
  tab_style(
    style = list(
      cell_fill(color = "lightcyan")
    ),
    locations = cells_body(
      columns = everything(),
      rows = group == "website"
    )
  )
```

We also speak of "controlling for" other variables that might provide alternate explanations for any effect that is found. Based on the schedule of assignments, it is not possible to access the notes on the website before the reading questions are due, so everyone in the treatment group would have to do their work out of order. To rule timing out as a potential cause of different levels of understanding, we would want to control for time by ensuring that the two versions of the notes were released at the same time.

### Random Assignment

**Random Assignment**
:    The process of assigning subjects to either the treatment or control group in a random fashion, where they're equally likely to be assigned to each group.

Because we are conducting an experiment, we are intervening in the process and directly assigning subjects to either the treatment (pdf readers) and control (website readers). There are many ways we could do this. The morning sections could all be assigned the pdf and the afternoon sections the website. Or the instructors could choose to exclusively assign either the pdf or the website version of the notes to their individual sections.

The problem with both of these approaches is that our two groups might differ on more characteristics than just their reading format. The morning sections perhaps have students who are early risers and more conscientious students. Or perhaps the instructors who choose the website are more tech-savvy and more effective at teaching computing. In both cases, we invite the skeptical observer to question whether it was truly the medium of the notes that led to a difference in course grades or if it was something else.

The mechanism of random assignment is brilliant because it can snuff out every such skeptical inquiry in one fell swoop. If instead we assigned each student to read the pdf or the website totally at random, every other possible characteristic between these groups should, on average, be balanced. If students are assigned at random, we'd expect an equal number of early-risers to be in both the pdf and the website group. We'd also expect the students with the more effective instructors to be evenly represented in both groups. And so on and so forth, for every possible other characteristic that might muddy the waters of our causal claim.

### Replication

**Replication**
:    The practice of assigning multiple subjects to both the treatment and control group. Also, the practice of repeating an experiment a second time to see if the result is consistent.

The careful reader will have noted a weakness in the brilliance of the random assignment mechanism for balancing the characteristics between the groups. What if, purely due to bad luck, we happen to randomly assign all of the early-risers to the pdf group and all of the late-risers to the website group? That would indeed bring us back to the problem of there being many ways in which our treatment group is different from our control group.

The random assignment mechanism will balance out all possible confounding factors *on average*, but for a given experiment that is not guaranteed. However, it becomes much more likely if we have a large sample size. If you just have four students total in the class, two of whom are early risers, it's quite easy for both of them to end up in the pdf group if they were assigned at random. If instead you have 800 students, 400 of whom are early risers, it's very very unlikely that all 400 will have made their way into the pdf group.


### Other considerations

Randomized controlled trials have long been considered the gold standard for establishing a group-level causal claim, but care must be taken to ensure that your result means what you think it means. Here we reconsider a study where a new drug was used to treat heart attack patients. In particular, researchers wanted to know if the drug reduced deaths in patients.

These researchers designed a randomized control trial because they wanted to draw causal conclusions about the drug’s effect. Study volunteers were randomly assigned to one of two study groups. One group, the treatment group, received the drug. The control group did not receive any drug treatment.

Put yourself in the place of a person in the study. If you are in the treatment group, you are given a fancy new drug that you anticipate will help you. If you are in the control group, you are not treated at all but instead sit by idly, knowing you are missing out on potentially life-saving treatment. These perspectives suggest there are actually two effects in this study: the one of interest is the effectiveness of the drug, and the second is the emotional effect of (not) taking the drug, which is difficult to quantify.

In order to control for the emotional effect of taking a drug, the researchers decide to hide from patients which group they are in. When researchers keep the patients uninformed about their treatment, the study is said to be *blind*. But there is one problem: if a patient does not receive a treatment, they will know they’re in the control group. A solution to this problem is to give a fake treatment to patients in the control group. This is called a *placebo*, and an effective placebo is the key to making a study truly blind. A classic example of a placebo is a sugar pill that is made to look like the actual treatment pill. However, offering such a fake treatment may not be ethical in certain experiments. For example, in medical experiments, typically the control group must get the current standard of care. Oftentimes, a placebo results in a slight but real improvement in patients. This effect has been dubbed the placebo effect.

The patients are not the only ones who should be blinded: doctors and researchers can also unintentionally affect the outcome. When a doctor knows a patient has been given the real treatment, they might inadvertently give that patient more attention or care than a patient that they know is on the placebo. To guard against this, which again has been found to have a measurable effect in some instances, most modern studies employ a *double-blind* setup where doctors or researchers who interact with patients are, just like the patients, unaware of who is or is not receiving the treatment.

<!-- ## Correlation and Causation: the history of Smoking and Cancer -->

## Summary

We set the stage for reasoning about causation by defining cause and effect in terms of a conditional counterfactual. We say "A causes B" if, in a world where A didn't happen, B no longer happens.

This definition is problematic if we intend to establish causes using only data. While we are never able to actually observe all of the data necessary to prove a causal claim absolutely, there are many methods that have been devised to approximate the counterfactual. Chief among these is the randomized control trial (RCT). RCTs are able to isolate the effect of interest by creating a carefully selected control group and then assigning subjects to groups at random. When the number of replicates is large enough, we can be confident that our control group on average serves as a close counterfactual to our treatment group.

\

[ ]{.column-margin}


![Illustration by Mayaan Hayal[^frost]](images/frost.png){fig-align="center" width="300px"}

[^frost]: A drawing from "The Book of Why" depicting the notion of potential outcomes described in Robert Frost's poem [The Road Not Taken](https://www.poetryfoundation.org/poems/44272/the-road-not-taken).

