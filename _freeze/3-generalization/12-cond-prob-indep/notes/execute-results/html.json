{
  "hash": "804fc9b2abbb32371839058926b84c07",
  "result": {
    "markdown": "---\ntitle: \"How to Calculate Chances\"\nsubtitle: \"Two important ideas: Conditional probabability and Independence\"\ndate:  \"2/24/2023\"\nimage: images/sally-clark-headline.jpeg \n---\n<!-- The bit before that is commented out adds publish date to document metadata and button links at the top of the doc. This workflow can be revisited but currently doesn't work because listings aren't updated with these dates, only the renderd docs. -->\n\n::: {.cell}\n\n:::\n\n\n\n[[Discuss]{.btn .btn-primary}](https://edstem.org/us/courses/31657) [[Reading Questions]{.btn .btn-primary}](https://www.gradescope.com/courses/477232) [[PDF]{.btn .btn-primary}](notes.pdf)\n\n\n\n\\\n\n\n\n\n::: {.cell}\n\n:::\n\n\n## Sally Clark: a tragic victim of statistical illiteracy\n\n![Sally Clark after her successful appeal](images/sally-clark.png){fig-align=center width=\"250\"}\n\n[^1]: (https://www.theguardian.com/uk-news/2021/nov/20/sally-clark-cot-death-mothers-wrongly-jailed)\n\n[I]{.dropcap}n November 1999, Sally Clark, an English solicitor, was convicted of murdering her infant sons[^1]. The first, Christopher, had been 11 weeks old when he died, in 1996, and the second, Harry, 8 weeks old, in January 1998, when he was found dead. Christopher was believed to have been a victim of \"cot death\", called SIDS (Sudden Infant Death Syndrome) in the US. After her second baby, Harry, also died in his crib, Sally Clark was arrested for murder. The star witness for the prosecution was a well known pediatrician and professor, Sir Roy Meadow, who authored the infamous Meadow's Law :\"One sudden infant death is a tragedy, two is suspicious and three is murder until proved otherwise\"[^2]. Unfortunately it was easier to comprehend this \"crude aphorism\" than make the effort to understand the subtleties of conditional probability. The Royal Statistical Society protested the misuse of statistics in courts, but not early enough to prevent Sally Clark's conviction. She was eventually acquitted and released, only to die at the age of 42 through alcohol poisoning[^3] The math presented by Meadow, in brief: Based on various studies, there is a chance of 1 in 8,543 of a baby dying of SIDS in a family such as the Clarks. As the Clarks suffered *two* deaths, Meadow multiplied 8,543 by 8,543 to arrive at 73 million. He told the jury that the chance that the event of two \"cot deaths\" was 1 in 73 million. The defense did not employ a statistician to refute her claim, a choice that may have been disastrous for Sally Clark.\n\n[^2]: From the archives of The Guardian newspaper <https://www.theguardian.com/uk/2001/jul/15/johnsweeney.theobserver>\n\n[^3]: The thumbnail image of the headline from the Manchester Evening News and some details of the case are from <http://www.inference.org.uk/sallyclark>\n\nWe will revisit this case at the end of these notes. Now, let's talk about the *conditional probability* of an event.\n\n## Computing chances\n\nIn the previous set of notes, we learned about outcome spaces, events, and their probabilities. If two events were mutually exclusive$ P(A \\cap B) = \\emptyset$, we can compute the probability of at least one of the events occuring ($A\\cup B$) using the addition rule $P(A \\cup B) = P(A) + P(B)$. These notes are about how we compute probabilities when two events are *not* mutually exclusive. \n\n#### Example 1: Drawing red and blue tickets from a box\n\nConsider a box with four tickets in it, two colored red and two blue. Except for their color, they are identical: ![](images/box-red-blue.jpeg){width=\"100\"}. Suppose we draw three times at random from this box, with replacement. List all the possible outcomes. What is the chance of seeing exactly 2 red cards among our draws?\n\n<details>\n\n<summary>Check your answer</summary>\n\nNote that since each of the cards is equally likely to be drawn, therefore all the sequences of three cards are equally likely. We can count the number of possible outcomes that contain exactly 2 red cards, and divide that number by the number of total possible outcomes to get the chance of drawing exactly 2 red cards:\n\n![](images/rb-box-3-draws.jpeg){fig-align=\"center\" width=\"600\"} There are three outcomes that have exactly two cards, out of a total of 8 possible outcomes, so the chance of exactly two red cards in three draws at random with replacement is 3/8.\n\n</details>\n\nNow suppose we repeat the procedure, but draw *without* replacement. What is the chance of exactly 2 red cards in 3 draws?\n\n<details>\n\n<summary>Check your answer</summary>\n\n![](images/rb-box-3-draws-no-repl.jpeg){fig-align=\"center\" width=\"550\"}\n\nNotice that we have fewer possible outcomes (6 instead of 8, why?), though they are still equally likely. Again, there are 3 outcomes that have exactly 2 red cards, and so the chance of 2 red cards in three draws is now 3/6.\n\n</details>\n\nWhat about the probability distribution table for the number of red cards in three draws? Write down the probability distribution table for the number of red cards in three draws from a box with 2 red cards and 2 blue cards, while drawing *with* replacement, and then write down the probability distribution table for the same quantity (number of red cards in three draws from a box with 2 red cards and 2 blue cards), when you draw the tickets  *without* replacement:\n\n<details> <summary>Check your answer</summary>\n\n<center>\n\n<!-- <div style=\"width:300px\"> -->\n\n| Number of reds in 3 draws |  Chance, with replacement   | Chance, without replacement |\n|:---------------:|:--------------------------:|:--------------------------:|\n|       0 red tickets       | $\\displaystyle \\frac{1}{8}$ |             $0$              |\n|       1 red ticket        | $\\displaystyle \\frac{3}{8}$ | $\\displaystyle \\frac{3}{6}$ |\n|       2 red tickets       | $\\displaystyle \\frac{3}{8}$ | $\\displaystyle \\frac{3}{6}$ |\n|       3 red tickets       | $\\displaystyle \\frac{1}{8}$ |             $0$              |\n\n<!-- </div> -->\n\n</center>\n\nWhy are the numbers different? What is going on?\n\n</details>\n\nBelow you see an illustration of what happens to the box when we draw *without* replacement.\n\n![](images/without-repl-1.jpeg){fig-align=\"center\" width=\"600\"}\n\nWe see that the box (our access frame) reduces after each draw. After two draws, if the first 2 draws are red (as on the left most sequence) you can't get another red ticket, whereas if you are drawing *with* replacement, you can keep on drawing red tickets. (Note that the outcomes in the bottom row are not equally likely, since on the left branch of the tree, blue is twice as likely as red to be the second card, so the outcome RB is twice as likely as RR, and the outcome BR on the right branch of the tree is twice as likely as BB.)\n\n### Rules of probability (recap)\n\nRecall the rules of probability and the terms we have seen so far. Suppose we have some action such as tossing a coin, drawing from a box etc. for which we know all the *possible* results from this action, but we don't know *which* particular one will occur on any instance of the action. This action is called a random *experiment*.  All the possible things that can happen are called outcomes, and the collection of all the outcomes is called the *sample space* or *outcome space*  $\\Omega$. If $A$ is a subset of $\\Omega$, we call $A$ an *event*. What can we say about $A$ and $\\Omega$?\n\n1. $\\Omega$ is the set of all possible outcomes. <details> <summary> What is the chance of $\\Omega$? </summary> \nThe chance of $\\Omega$ is 1. It is called the *certain* event. \n</details>\n\n2. When an event has **no** outcomes in it, it is called the *impossible* event, and denoted by \n$\\emptyset$. <details> <summary> What is the chance of the impossible event?</summary> \nThe chance of $\\emptyset$ is 0.\n</details>\n\n3. Let $A$ be a collection of outcomes (for example, from the example above, $A$ could be the event of two red tickets in 3 draws with replacement). \n<details> <summary>Then the chance of $A$ has to be ______ (fill in the blank with a suitable phrase) </summary> \n between 0 and 1.\n </details>\n \n4. If $A$ and $B$ are two events with no outcomes in common, <details> <summary> then they are called ______ (fill in the blank with a suitable phrase) .</summary> \n mutually exclusive.\n  </details>\n  \n5. Consider an event $A$. The chance of an outcome *not* being in $A$ is 1 minus the chance of $A$, since the total chance is $1$. $A^C$ denotes the event of not being in $A$.\n  \n#### Example 2: Drawing tickets from a box to represent the number of heads in 3 tosses\n\nIf we are setting up a box for modeling the number of heads in three tosses of a fair coin, would either of the boxes below work? If not, say why not, and correct the box.\n\n(a) ![](images/coin.jpeg){width=\"100\"} - Draw three times at random with replacement, and sum the draws.\n(b) ![](images/coin-wrong.jpeg){width=\"150\"}-  Draw once, the result is the number of heads.\n\n<details> <summary> Check your answer </summary> \nThe first box is correct and represents a box model for this situation. The second box doesn't work because the tickets do not represent equally likely events. If you toss a fair coin 3 times and count the number of heads, the probability distribution of the number of heads is the same as when you draw a ticket three times at random with replacement from a box with 2 red tickets and 2 blue, and count the number of red tickets (the probability distribution above, in Example 1). If we wanted to use this example, we would have to create a different box that reflects the probability distribution of the number of heads in 3 tosses with equally likely tickets:\n\n![](images/coin-3-tosses.jpeg){width=\"300\"}\n  \n### Conditional probabilities \n\nIn Example 1 above, we saw that the probability of a red ticket on a draw changes if we sample without replacement. If we get a blue ticket on the first draw, the chance of a red ticket on the second draw is 2/3 (since there are 3 tickets left, of which 2 are blue). \nIf we get a red ticket on the first draw, the chance of a red ticket on the second draw is 1/3. These chances - that *depend* on what happened on the first draw are called *conditional probabilities*. If $A$ is the event of a blue ticket on the first draw, and $B$ is the event of a red ticket on the second draw, we say that the chance of $B$ *given* $A$ is 2/3, which is a *conditional* probability, because we put a condition on the first card, that it had to be blue. \n\nWhat about if we don't put a condition on the first card? What is the chance that the second card is red? \n<details> <summary> Check your answer </summary> \nThe chance that the second card drawn is red is 1/2, if we don't have any information about the first card drawn. To see this, it is easier to imagine that we can shuffle all the cards in the box and they are put in some random order in which each of the 4 positions is equally likely. There are 2 red cards, so the chance that a red card will occupy any of the 4 positions, including the second, is 2/4.\n</details>\n\nThis kind of chance, where we put no condition on the first card, is called an *unconditional* probability - we don't have any information about the first card.\n\n##  The Multiplication Rule: computing the probability of an intersection\n\nWe often want to know the probability that two (or more) events will *both* happen: What is the chance if we roll a pair of dice, that both will show six spots; or if we deal two cards from a standard 52 card deck, that both would be kings, or in a family with two babies, both would suffer SIDS. \nWhat do we know? Recall what the Venn diagram of intersectiing events looks like:\n\n![](images/venn-diagram-intersection.png){fig-align=center width=\"300\"}\n\nThis picture tells us that $A\\cap B$ is contained in both $A$ and $B$, so its probability should be less than both the probabilities of $A$ and $B$: $P(A\\cap B) \\le P(A), P(B)$. In fact, we write the probability of the intersection as:\n\n$$P(A \\cap B) = P(A) \\times P(B|A)$$\nThe second probability on the right-hand side of the equation is called the *conditional* probability of $B$ *given* $A$. For example, in the first example with the box with two red and two blue cards, if $A$ is the event of drawing a red card on the first draw, and $B$ is the event of drawing a blue card on the second draw, when we draw two cards *without* replacement, then \nwe have that $P(A) = \\displaystyle \\frac{2}{4}$, $P(B | A) =  \\displaystyle \\frac{2}{3}$ (the denominator reduces by one, since there are only 3 cards left in the box, of which 2 are blue). Therefore: \n\n$$P(A \\cap B) = P(A) \\times P(B|A) = \\frac{2}{4} \\times \\frac{2}{3} = \\frac{1}{3}$$\nThis becomes more clear if we think about the frequentist theory. We draw a red card first about half the time in the long run (if we think about drawing a card over and over again). Of those times, we would *also* draw a blue card second about two-thirds of the time, since a drawing a blue card would be twice as likely as drawing a red card. Therefore drawing a red card first and then a blue card would happen two thirds of one half of the time, which is about a third of the time.\n\nNote that the roles of $A$ and $B$ could be reversed in the expression above:\n\n$$ P(A \\cap B) = P(A) \\times P(B | A) = P(B) \\times P(A | B)$$\nThis gives us a way to compute the conditional probability:\n\n$$  P(B | A) = \\frac{ P(A \\cap B)}{P(A)}, \\; \\; P(A) > 0 $$\n\n:::{.callout-important icon=false}\nNote that $P(A | B)$ and $P(B | A)$ can be very different.\nConsider the scenario shown in the Venn diagram here:\n![](images/cond-prob-warning.png)\n:::\n## Independence\n\nWe say that two events are *independent* if the chances for the second remain the *same* even if you know that the first has happened, no matter how the first event turns out. Otherwise, the events are *dependent*. That is, if $A$ and $B$ are independent, then we have that $P(A | B) = P(A)$ and $P(B |A) = P(B)$. This means that the multiplication rule reduces to:\n\n$$ P(A \\cap B) = P(A) \\times P(B | A) = P(A) \\times P(B) $$\n\nYou can check for independence by computing $P(A \\cap B)$ and $P(A)\\times P(B)$ and seeing if they are equal.\n\nFor example, consider our box of red and blue tickets. When we draw *with* replacement, the chance of a red ticket on the second draw given a blue ticket on the first draw remains at 1/2. If we had a red ticket on the first draw, the chance of the second ticket being red is *still* 1/2. The chance doesn't change because it does not *depend* on the outcome of the first draw, since we put the ticket back. \n\nIf we draw the tickets *without* replacement, we have seen that the chance changes. The chance of a blue ticket on the second draw given a red ticket on the first draw is 2/3, but the chance of a red ticket on the second draw given a red ticket on the first is 1/3. \n\nThe lesson here is that when we draw tickets *with* replacement, the draws are **independent** - the outcome of the first draw does not affect the second. If we draw tickets *without* replacement, the draws are **dependent**. The outcome of the first draw changes the chances of the tickets for the second draw.\n\n#### Example 3: Selecting 2 people out of a group of 5 \n##### (drawing *without* replacement)\nWe have a group of 5 people: Alex, Emi, Fred, Max, and Nan. Two of the five are to be selected at random to form a two person committee. Draw the box model for this situation.\n\n<details><summary>Check your answer</summary>\n\n![](images/committee.jpeg){fig-align=center width=\"600\"}\n\nAll the ten pairs are equally likely. On the first draw, there are 5 tickets to choose from, and on the second there are 4, making $5 \\times 4 = 20$ possible draws of two tickets, drawn from this box, one at a time, without replacement. We have only 10 pairs here because of those 20 pairs, there are only 10 distinct ones. When we count 20 pairs, we are counting Alex $+$ Emi as one pair, and Emi $+$ Alex as another pair.  \n</details> \n\nWhat is the chance that Alex and Emi will be selected? Guess! (Hint: you have seen all the possible pairs above, and they are equally likely. What will be the chance of any one of them?) \n\nWe could use the multiplication rule to compute this chance, which is *much* simpler than writing out all the possible outcomes. The committee can consist of Alex and Emi either if Alex is drawn first **and** Emi second, **or** Emi is drawn first **and** Alex second. The chance that Alex will be drawn first is $1/5$. The conditional chance that Emi will be drawn second *given* that Alex was drawn is $1/4$ since there are only 4 tickets left in the box. Using the multiplication rule, the chance that Alex will be drawn first and Emi second is $(1/4) \\times (1/5) = 1/20$. Similarly, the chance that Emi will be drawn first and Alex second is $1/20$. This means that the chance that Alex and Emi will be selected for the committee is $1/20 + 1/20 = 1/10$.\n\n\n#### Example 4: Colored and numbered tickets\n\nI have two boxes that with numbered tickets colored red or blue as shown below. \n\n![](images/indep-box.jpeg){fig-align=center width=300}\n\n\nAre color and number independent or dependent for box 1? What about box 2? \n\nFor example, is the chance of a ticket marked 2 the same whether the ticket is red or blue?\n\n<details><summary>Check your answer</summary>\n\nFor box 1, color and number are dependent, since the chance of 3 given that the ticket is red is 1/3, but the chance of 3 given that the ticket is blue is 0 (and similarly for the chance of 4).\n\nEven though the chance for 1 or 2 given the ticket is red is the same as the chance for 1 or 2 given the ticket is blue, we say that color and number are *dependent* because of the tickets marked 3 or 4.\n\n</details>\n\n#### Example 5: Tickets with more than one number on them\n\nNow I have two boxes that with numbered tickets, where each ticket has two numbers on them, as shown. For each box, are the two numbers independent or dependent. For example, if I know that the first number is 1 does it change the chance of the second number being 6 (or the other way around: if I know the second number is 6, does it change the chance of the first number being 1)?\n\n![](images/box-2-number.jpeg){fig-align=center width=400}\n<details><summary>Check your answer</summary>\n\nFor box 1, the first number and second number are independent, as shown below, using 1 and 6 as examples. If we know that the first number is 1, the box reduces as shown. The chance of the second number being 6 does not change for box 1. The chance *does* change for box 2, increasing from 1/2 to 2/3, since the second number is more likely to be 6 if the first number is 1.\n\n![](images/box-2-number-cond.jpeg){fig-align=center width=750}\n</details>\n\n#### Example 6: Back to Sally Clark\n\nProfessor Roy Meadow claimed that the chance of two of Sally Clark's sons dying of SIDS was 1 in 73 million. He obtained this number by multiplying 8543 by 8543, using the multiplication rule, treating the two events as *independent*. The question is, are they really independent? Was a crime really committed? Unfortunately for Sally Clark, two catastrophic errors were committed in her case by the prosecution, and not caught by the defense. (She appealed the decision, and was acquitted and released, but after spending 4 years in prison, accused of murdering her babies.)\n\nThe first error was in treating the deaths as independent, and the second was in looking at the wrong probability. Let's look at the first mistake. It turns out that the chance of a second child dying of \"cot death\" or SIDS is 1/60 *given* that the first child died of SIDS. This was a massive error, and it turned out that the prosecution suppressed the pathology reports for the second baby, who had a very bad infection and might have died of that. It is also believed that male infants are more likely to suffer cot death. \n\nThe second error is an example of what is called the Prosecutor's Fallacy. They looked the chance of the evidence if Sally Clark were innocent. They should have actually compared the chance of innocence given the evidence with the chance of murder given the evidence. These multiple errors ruined many lives. Though Sally Clark was eventually acquitted, helped by the Royal Statistical Society's evidence, her life was shattered, and she died soon after being released. The moral of this story is to be very careful while multiplying probabilities. You must check for independence. \n\n## Mutually exclusive vs independent events\n\nNote that if two events $A$ and $B$, both with positive probability, are mutually exclusive, they **cannot** be independent. If $P(A \\cap B) = 0$, but neither $P(A) =0$ nor $P(B) = 0$, then $P(A \\cap B) = 0 \\ne P(A)\\times P(B)$.\n\nIntuitively, they are opposite scenarios. Independence of two events means that knowing one of the events happens gives you no information about the probability of the other, and if two events are mutually exclusive, knowing one of the events happens tells you that the other cannot happen. \n\n## Inclusion-exclusion (generalized addition rule)\n\nNow that we know how to compute the probability of the intersection of two events, we can compute the chance of the union of two events:\n\n![](images/incl-excl.png){fig-align=center width=\"400\"}\n\n$$P(A \\cup B) = P(A) + P(B) - P(A \\cap B) $$\n\nYou can see that if we just add the chances of $A$ and $B$, we double count the overlap. By subtracting it once, we can get the correct probability, and we know how to compute the chance of $A\\cap B$. This is known as the inclusion-exclusion principle. \n\n\n\n## Summary\n\nIn this lecture, we do a deep dive into computing chances. It is well known that people are just not good at estimating chances of events, and we saw the tragic example of Sally Clark (who, even more sadly, is not a unique case)[^js]. \n\nWe defined conditional probability and independence, and the multiplication rule, considering draws at random with and without replacement. \n\nWe noted that independent events are very different from mutually exclusive events, and finally we learned how to compute probabilities of unions of events that may not be mutually exclusive.\n\n\n[^js]: <https://www.theguardian.com/uk-news/2021/nov/20/sally-clark-cot-death-mothers-wrongly-jailed>\n\n[^mh]: image from Wikipedia <https://en.wikipedia.org/wiki/Monty_Hall_problem>",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}