{
  "hash": "28e0d65dc586339c7f5351eea7db040b",
  "result": {
    "markdown": "---\ntitle: \"From Samples to Populations\"\nsubtitle: \"The bias and variance of moving from sample to population.\"\ndate:  \"3/6/2023\"\nformat:\n  html: default\n  pdf: default\n---\n\n<!-- The bit before that is commented out adds publish date to document metadata and button links at the top of the doc. This workflow can be revisited but currently doesn't work because listings aren't updated with these dates, only the renderd docs. -->\n\n\n::: {.cell}\n\n:::\n\n\n\n\n[[Discuss]{.btn .btn-primary}](https://edstem.org/us/courses/31657) [[Reading Questions]{.btn .btn-primary}](https://www.gradescope.com/courses/477232) [[PDF]{.btn .btn-primary}](notes.pdf)\n\n\n\n\\\n\n:::{.content-hidden unless-profile=\"staff-guide\"}\n## Learning Objectives\n\n#### Concept Acquisition\n\n#### Tool Acquisition\n\n- `slice_sample()`\n- `rep_slice_sample()`\n\n#### Concept Application\n\n#### Key Terms\n\n- sample\n- population\n- population parameter\n- selection bias\n- non-response bias\n- measurement bias\n- sampling variability\n- measurement variability\n- random assignment\n\n---------------------------\n\n:::\n\n[G]{.dropcap}eneralization is the process of using a subset of information to draw conclusions about some broader set or phenomenon. It is powerful - it allows us to draw conclusions about things we have not observed - but it is tricky to do well. In these notes, you will learn the sources of error that can creep in when making a generalization.\n\n![](images/generalization.png){width=\"200\" fig-align=\"center\"}\n\nThere are four terms that you will see come up again and again as we discuss generalization. They familiar terms that have tightly coupled meanings, so we present them together.\n\n**Sample**\n: The subset of units that are observed, measured, and analyzed. Commonly referred to as a data set. The size of the sample is indcated by $n$.\n\n**Population**\n: The set of units from which your sample is drawn. The size of the population is indicated by $N$.\n\n**Statistic**\n: A numerical summary of a sample. Examples include a sample mean, a sample median, a sample proportion, a sample correlation coefficient, and an estimated coefficient of a linear model.\n\n**Population Parameter**\n: A numerical summary of a population. Every statistic of a sample has an analog in the population (population mean, population proportion, etc).\n\nTo see how these terms interrelate and to introduce the sources of error that can creep in while generalizing from a sample to a population, let's look a scenario.\n\n### What year are my students?\n\nOn the first day of class, the professor strides into Pimentel Hall to present a lecture to a new crop of students. If you have not yet had the pleasure of having a class in Pimentel, it looks like this.\n\n![](images/pimentel-sm.jpeg){fig-align=\"center\" width=\"350\"}\n\n[^pimentel]: Photo of Pimentel Hall by flickr user TheRealMichaelMoore.\n\nPimental is the second largest lecture hall at Cal, with exactly 527 seats. On this first day of class, the room is packed and all 527 of the students registered for Stat 20 are in the hall.\n\nEager to ensure that the lecture is calibrated to the interest and experience of the students, the professor seeks to learn how many years they have been at Cal. The professor calls on a student sitting in the middle of the front row and asks, \"What year are you at Cal?\" The student replies, \"sophomore\", so the professor write 2 on the board. The professor proceeds to repeat this question to all of the students sitting in the 18 seats at the front row of Pimentel. By the end, there is a data frame on the board with one column and 18 rows, the first three of which read\n\n| Year |\n|:----:|\n|  2   |\n|  1   |\n|  1   |\n\nEver the statistician, the professor then visualizes the distribution of data by sketching on the board a bar chart and jots down the sample mean, which is 1.77.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\npimentel <- data.frame(year = c(2, 1, 1, 1, 2, 2, \n                                4, 1, 1, 3, 3, 1, \n                                2, 2, 2, 1, 2, 1))\n\npimentel %>%\n  ggplot(aes(x = year)) +\n  geom_bar()\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-pdf/unnamed-chunk-3-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n\nHow good of an answer is 1.77 to the professors question of, \"What year are my students?\"\n\n#### Identifying the components\n\nIn this setting, the population is the set of all $N = 527$ students in Pimentel. That is the set of units (students) that the professor seeks to understand and from which the sample is drawn. The sample is the subset of $n = 18$ students who were sitting in the front row and who were asked their age. The sample mean, $\\bar{x} = 1.77$, is an example of a statistic. Other statistics that could be calculated from the sample include the median (2) and the mode (1). These statistics be used to estimate their analogs in the population, such as the population mean, $\\mu$. The value of $\\mu$ is what the professor seeks to learn, but at this point is still unknown.\n\nUsing this terminology, we can ask the question again: how good of an estimate of the mean year of the entire class is the sample mean, 1.77? How much error did we incur when generalizing and where did that error come from?\n\n## Sources of Error\n\nTo understand the forms that estimation error can take, consider the analogy of darts thrown at a dart board. The center of the dart board represents the parameter that we are trying to hit and each dart that we throw represents a statistic calculated from a sample. There are two ways in which a dart throw can miss the bullseye. One way is that we could systematically tend to throw above and to the left of the bullseye. This form of error is called bias. Another way that our dart-throwing could miss the bullseye is if we are an erratic thrower and one throw tends to be very different from this next. This form of error is called variation.\n\n![](images/bullseye.png){fig-align=center width=\"370\"}\n\nIf a sample is *representative* of the population, there is no bias present. That is represented by the top row of bullseyes.\n\n### Types of Statistical Bias\n\nStatistical bias comes in many forms. Here we describe two of the most important types.\n\n**Selection bias**\n:    When the mechanism used to choose units for the sample tends to select certain units more often than they should.\n\nAs an example, a *convenience sample* chooses the units that are most easily available. Problems can arise when those who are easy to reach differ in important ways from those harder to reach. Another example of selection bias can happen with observational studies and experiments. These studies often rely on volunteers (people who choose to participate), and this self-selection has the potential for bias if the volunteers differ from the target population in important ways.\n\n**Measurement bias**\n:    When your process of measuring a variable systematically misses the target in one direction.\n\nFor example, low humidity can systematically give us incorrectly high measurements for air pollution. In addition, measurement devices can become unstable and drift over time and so produce systematic errors. In surveys, measurement bias can arise when questions are confusingly worded or leading, or when respondents may not be comfortable answering honestly.\n\nBoth of these types of bias can lead to situations where the data are not centered on the unknown targeted value. A common method to address selection bias is to draw a *simple random sample*, where each unit from the population is equally likely to be drawn. A pilot survey can improve question wording and so reduce measurement bias. Procedures to calibrate instruments and protocols to take measurements in, say, random order can reduce measurement bias.\n\nBias does not need to be avoided under all circumstances. If an instrument is highly precise (low variance) and has a small bias, then that instrument might be preferable to another that has high variance and little to no bias. Biased studies can be useful to pilot a survey instrument or to capture useful information for the design of a larger study.\n\n#### Statistical Bias in Pimentel\n\nThe method used by the professor likely suffers from statistical bias. The units that were drawn into the sample (the 18 students in the front row who were called on) constitute a convenience sample - they were sampled because they were easy to sample. That is not necessarily a problem, but there is good reason to think that students of all years are not equally likely to sit in the front row. First year students, bright-eyed and bushy tailed with enthusiasm, will be more likely to sit in the front row. If that is true, the professor incurred selection bias that will lead to an estimate of the population mean that is too low.\n\nWhat about measurement bias? In this case, the process of measuring a student's year involves the act of asking them a question, hearing their answer, and writing it on the board. How could this be systematically in error? One way would be if first year students occasionally lie about their year when asked, for fear of being thought of as an over-eager over-achiever. If this were true, then lots of the 2s that we recorded were in fact 1s, and the estimate of 1.77 would be too high.\n\nWhether or not bias is present, data typically also exhibit variation. Variation can be introduced purposely by using chance to select a sample, and it can occur from an instrumentâ€™s precision or natural variation.\n\n\n### Types of Variation\n\nVariation that results from a chance mechanism has the advantage of being quantifiable.\n\n- Sampling variation results from using chance to take a sample. We can in principle compute the chance a particular sample is selected.\n\n- Measurement error for instruments result from a measurement process. If the instrument has no drift and a reliable distribution of errors, then when we take multiple measurements on the same object, we get variations in measurements that are centered on the truth.\n\n\n+ Assignment variation of units to treatment groups in a controlled experiment produces variation. If we split the units up differently, then we can get different results from the experiment. This randomness allows us to compute the chance of a particular group assignment.\n\nThe Box Model is a simple abstraction that can be helpful for understanding variation. This model helps us reason about sampling schemes, randomized controlled experiments, and measurement error. It is the topic of the next section.\n\n### Bias\n\n**Selection Bias**\n\n*sampling weights*\n*probability sample*\n*convenience sample*\n\n**Measurement Bias**\n\n\n\n### Variability\n\n- sampling variability\n- measurement variability\n\n## The Sampling Distribution\n\nSketch of triptych\n\n[^class-survey]\n\n[^class-survey]: This population distribution is taken from the distribution of several years worth of data collected during the class survey (`class_survey` in `stat20data`). ![](images/class-survey-pie-chart.png){.column-margin}\n\n**Sampling Distribution**\n\n: The distribution of a statistic upon repeated sampling. Generally. unknowable but we will learn how to approximate it.\n\n## Drawing Samples from Population\n\nGod-mode looking at class survey\n\n### Scenario 1: How it usually goes down\n\nask students in front row\n\ngo through forms of bias and variability\n\n\n### Scenario 2: SRS\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## The Ideas in Code\n\n#### `slice_sample()`\n\nThe workhorse function to generate samples of data from a data frame is `slice_sample()`. This function takes a random sample of rows from a data frame. This function is in the `tidyverse` package. Useful arguments include:\n\n- `n`: the sample size.\n- `replace`: `TRUE` or `FALSE`. whether to sample rows with or without replacement.\n- `weight_by`: a column from the original data frame to use as sampling weights for each row.\n  \n##### Example 1\n\nTreat the `penguins` data set as your population. Take a random sample of three penguins, without replacement, from the `penguins` data frame where each of the penguins is equally likely.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(stat20data)\n\nset.seed(35)\npenguins %>%\n  slice_sample(n = 3,\n               replace = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 8\n  species   island bill_length_mm bill_depth_mm flipper_le~1 body_~2 sex    year\n  <fct>     <fct>           <dbl>         <dbl>        <int>   <int> <fct> <int>\n1 Chinstrap Dream            43.5          18.1          202    3400 fema~  2009\n2 Gentoo    Biscoe           45.1          14.4          210    4400 fema~  2008\n3 Chinstrap Dream            52.2          18.8          197    3450 male   2009\n# ... with abbreviated variable names 1: flipper_length_mm, 2: body_mass_g\n```\n:::\n:::\n\n\n\nObserve:\n\n- If you do not specify the sampling weights, the function will select each row with equal probability.\n- We set a seed so that everything this code is run, it will come up with the same sample of 12 rows. Try running this code yourself. Do you get the same sample?\n\n#### Example 2\n\nTake a random sample of three penguins without replacement using sampling weights proportional to the bill lengths; that is, a penguin with a bill length that is twice is long as another penguin should be twice as likely to be selected for the sample.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\npenguins %>%\n  slice_sample(n = 3, \n               replace = FALSE,\n               weight_by = bill_length_mm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 8\n  species   island bill_length_mm bill_depth_mm flipper_le~1 body_~2 sex    year\n  <fct>     <fct>           <dbl>         <dbl>        <int>   <int> <fct> <int>\n1 Chinstrap Dream            45.6          19.4          194    3525 fema~  2009\n2 Chinstrap Dream            51.3          19.9          198    3700 male   2007\n3 Adelie    Biscoe           45.6          20.3          191    4600 male   2009\n# ... with abbreviated variable names 1: flipper_length_mm, 2: body_mass_g\n```\n:::\n:::\n\n\n\nObserve:\n\n- While it is still possible for every penguin to be selected into the sample, the ones with longer bill lengths are more likely. The precise probability that the first penguin was selected was its bill length (43.5) divided by the sum of the bill lengths of all of the penguins in the population.\n\n\n#### `rep_slice_sample()`\n\nAn extension of `slice_sample()` that doesn't take just a single sample of size `n`, but repeats the process many times and draws many samples of size `n`. The useful new argument is `reps`, the number of replicates (or separate samples) you wish to generate. This function is in the `infer` package.\n\n##### Example 3\n\nTake two separate sample samples from the `penguins` data frame without replacement, and each of sample size three.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlibrary(infer)\npenguins %>%\n  rep_slice_sample(n = 3,\n                   replace = FALSE,\n                   reps = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 9\n# Groups:   replicate [2]\n  replicate species   island bill_length_mm bill_d~1 flipp~2 body_~3 sex    year\n      <int> <fct>     <fct>           <dbl>    <dbl>   <int>   <int> <fct> <int>\n1         1 Chinstrap Dream            52.7     19.8     197    3725 male   2007\n2         1 Adelie    Dream            41.5     18.5     201    4000 male   2009\n3         1 Gentoo    Biscoe           52.5     15.6     221    5450 male   2009\n4         2 Chinstrap Dream            43.2     16.6     187    2900 fema~  2007\n5         2 Gentoo    Biscoe           45       15.4     220    5050 male   2008\n6         2 Adelie    Biscoe           45.6     20.3     191    4600 male   2009\n# ... with abbreviated variable names 1: bill_depth_mm, 2: flipper_length_mm,\n#   3: body_mass_g\n```\n:::\n:::\n\n\n\nObserve:\n\n- The data frame produced by this function has a new column that has been appended to the left side: `replicate`. This column keeps track of which replicate the row belongs to. The first three rows constitute the first sample of size 3. The second three rows constitute the second sample of size 3.\n- The dimensions of the output data frame are 6 rows by 9 columns. Compare that to the dimensions of the original penguins data frame: 366 by 8. This function added one new column and contains `n` $\\times$ `reps` rows.\n\n:::{.content-hidden unless-profile=\"staff-guide\"}\n\n## Reading Questions\n\n(@) What source of error do you suspect will be most prominent.\n\n(@) What source of error do you suspect will be most prominent.\n\n(@) Def of sampling distribution\n\n(@) The `mtcars` data frame contains 11 different variables (including its horsepower, `hp`, and its miles per gallon, `mpg`) recorded on 32 different models of car. Treating this data frame as your population, which expression would you use to draw a random sample of size five without replacement, where each car is equally likely?\n\nYou're welcome to test this out before answering. `mtcars` is built into R.\n\n( ) `mtcars %>% slice_sample(n = 5, replace = FALSE)`\n\n( ) `mtcars %>% rep_slice_sample(n = 5, replace = FALSE, reps = 5)`\n\n( ) `mtcars %>% rep_slice_sample(n = 5, replace = TRUE)`\n\n( ) `mtcars %>% slice_sample(n = 5, replace = FALSE, weight_by = hp)`\n\n:::\n\n",
    "supporting": [
      "notes_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}