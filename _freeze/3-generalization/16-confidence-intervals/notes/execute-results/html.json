{
  "hash": "b710111f38ebe960a3d20593ff0b1fcd",
  "result": {
    "markdown": "---\ntitle: \"Confidence Intervals\"\nsubtitle: \"Quantifying the sampling variability of a statistic.\"\ndate:  \"3/8/2023\"\ntoc-depth: 4\n---\n<!-- The bit before that is commented out adds publish date to document metadata and button links at the top of the doc. This workflow can be revisited but currently doesn't work because listings aren't updated with these dates, only the renderd docs. -->\n\n::: {.cell}\n\n:::\n\n\n\n[[Discuss]{.btn .btn-primary}](https://edstem.org/us/courses/31657) [[Reading Questions]{.btn .btn-primary}](https://www.gradescope.com/courses/477232) [[PDF]{.btn .btn-primary}](notes.pdf)\n\n\n::: {.cell}\n\n:::\n\n\n\\\n\n[T]{.dropcap}he process of generalizing from a statistic of a sample to a parameter of a population is known as *statistical inference*. The parameter of interest could be a mean, median, proportion, correlation coefficient, the coefficient of a linear model . . . the list goes on. In the scenario that unfolded in Pimentel Hall, the parameter was the mean year of the 527 students in the class. The process of estimating that parameter by calculating the sample mean of the 18 students who decided to sit in the front row that day induces a sampling distribution.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npop_eager <- data.frame(year = rep(c(1, 2, 3, 4),\n                                   times = c(245, 210, 47, 25)),\n                        eagerness = rep(c(10, 6, 3, 1),\n                                        times = c(245, 210, 47, 25)))\nset.seed(55)\npop_eager <- pop_eager %>%\n  slice_sample(n = nrow(pop_eager))\n\nmu <- mean(pop_eager$year)\n\np_pop <- pop_eager %>%\n  ggplot(aes(x = year)) +\n  geom_bar(fill = \"purple\") +\n  labs(title = \"Population Distribution\",\n       y = \"\") +\n  annotate(\"point\", x = mu, y = -20, shape = 17, size = 5, color = \"goldenrod2\") +\n  theme_gray(base_size = 10) +\n  theme(plot.title = element_text(size=10))\n\nlibrary(infer)\nsamp_1 <- pop_eager %>%\n  slice_sample(n = 18,\n                   replace = FALSE,\n                   weight_by = eagerness)\n\nmany_samps <- samp_1 %>%\n  mutate(Sample = 1)\n\nfor (i in 2:500) {\n  many_samps <- pop_eager %>%\n    slice_sample(n = 18,\n                 replace = FALSE,\n                 weight_by = eagerness) %>%\n    mutate(Sample = i ) %>%\n    bind_rows(many_samps)\n}\n\nmany_xbars <- many_samps %>%\n  group_by(Sample) %>%\n  summarize(xbar = mean(as.numeric(year)))\n\nxlims_from_pop <- ggplot_build(p_pop)$layout$panel_scales_x[[1]]$range$range\n\np_samp_dist <- many_xbars %>%\n  ggplot(aes(x = xbar)) +\n  geom_bar(fill = \"steelblue\") +\n  lims(x = c(0, 4)) +\n  labs(title = \"Sampling Distribution\",\n       y = \"\",\n       x = expression(paste(bar(x), \" (mean year)\"))) +\n  annotate(\"point\", x = mu, y = -10, shape = 17, size = 5, color = \"goldenrod2\") +\n  theme_gray(base_size = 10) +\n  theme(plot.title = element_text(size=10)) +\n  lims(x = xlims_from_pop)\np_samp_dist\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=480}\n:::\n:::\n\n\nThis sampling distribution captures the two sources of error that creep in while generalizing. The horizontal offset from the middle of the sampling distribution to the population parameter (the gold triangle) represents the bias. The spread of the sampling distribution represents the variation. In these lecture notes you'll how to quantify sampling variability using two common tools.\n\n**Standard Error (SE)**\n: The standard deviation of the sampling distribution of a statistic.\n\n**Confidence Interval**\n: An interval of two values that represent lower and upper bounds on the statistic that capture most of the sampling distribution.\n\nTo focus on the variation, let's introduce a second example, one in which we will not need to worry about bias.\n\n\n## A Simple Random Sample\n\n##### Restaurants in San Francisco\n\nEvery year, the city of San Francisco's health department visits all the restaurants in the city and inspects them for food safety. Each restaurant is given an inspection score; these range from 100 (perfectly clean) to 48 (serious potential for contamination). \nWe have these scores from 2016. Let's build up to the sampling distribution bit by bit.\n\n <!-- ADD REF -->\n\n#### The Population Distribution\n\nOur population consists of the restaurants in San Francisco. Since the data are published online for all restaurants, we have a census[^census] of scores for every restaurant in the city.\n\n[^census]: The terms *census* refers to a setting where you have access to the entire population.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nload(url(\"https://www.dropbox.com/s/nbgw1uzj5ccwce2/fs_scores.rda?dl=1\"))\n\npop_dist <- ggplot(as.data.frame(fs_scores), aes(x=fs_scores, y=..density..)) + \n      geom_histogram(breaks=seq(47.5, 100.5, by = 1), \n                 color=\"black\", fill=\"gray\") + \n      xlab(\"Food Safety Scores\") +\n      ylab(\"Proportion\") +\n      ggtitle(\"Population Distribution\")\n\npop_dist\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=480}\n:::\n:::\n\n\nThe population distribution is skewed left with a long left tail. The highest possible score is 100. It appears that even scores are more popular than odd scores for scores in the 90s; in fact there are no scores of 99, 97, and 95. \n\nWe can calculate two parameters of this population:\n\n- The *population mean* is 87.6.\n- The *population SD* (aka the box SD) is 8.9.\n\n#### The Empirical Distribution\n\nAlthough we have data on all of the restaurants in the city, imagine that you're an inspector who has visited a simple random sample of 100 restaurants. That is, you draw 100 times without replacement from the population, with each unit equally likely to be selected. This leads to a representative sample that will have no selection bias.\n\nThe distribution of this sample (an empirical distribution) looks like:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(103122)\nsamp_scores <- sample(fs_scores, 100)\n\nemp_dist <- ggplot(as.data.frame(samp_scores), aes(x=samp_scores)) + \n      geom_histogram(breaks=seq(47.5, 100.5, by = 1), \n                 color=\"black\", fill=\"gray\") + \n      xlab(\"Food Safety Scores\") +\n      ylab(\"Proportion\") +\n      ggtitle(\"Empirical Dist. (Sample 1)\")\n\nemp_dist\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=480}\n:::\n:::\n\n\nThe sample statistics here are:\n\n- The *sample mean* is 86.27.\n- The *sample SD* is 9.9.\n\nObserve that the empirical distribution resembles the population distribution because we are using a sampling method without with selection bias. It's not a perfect match but the shape is similar. The sample average and the sample SD are also close to but not the same as the population average and SD.\n\n#### The Sampling Distribution\n\nIf you compared your sample to that of another inspector who took visited 100 restaurants, their sample would not be identical to yours, but it would still resemble the population distribution, and its mean and SD would be close to those of all the restaurants in the city. \n\nThe distribution of the possible values of the sample mean of a simple random sample of 100 restaurants is the sampling distribution of the mean (of the sample). We can use it to, for example, find the chance that the sample mean will be over 88, or the chance that the sample mean will be between 85 and 95. \n\nWe use simulation to approximate this distribution. We repeat 100,000 times the process of drawing a simple random sample of 100 restaurants.  The full distribution looks like: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(10312022)\nsamp_means <- replicate(100000, mean(sample(fs_scores, 100)))\n\nsampling_dist <- ggplot(as.data.frame(samp_means), \n                        aes(x=samp_means, y=..density..)) + \n      geom_histogram(bins = 45, \n                 color=\"black\", fill=\"gray\") + \n      xlab(\"Average Food Safety Scores\") +\n      ylab(\"Proportion\") +\n      ggtitle(\"Sampling Distribution\")\n\nsampling_dist\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=480}\n:::\n:::\n\n\nWe can consider numerical summaries of this distribution:\n\n- The *sampling distribution mean* is 87.6.\n- The sampling distribution SD, which is called the *Standard Error*, is 0.9. This convention of using a different name for the SD for the distribution of a statistic helps keep straight which kind of standard deviation we're talking about.   \n\nObserve that the sampling distribution of the sample mean doesn't look anything like the population or sample. Instead, it's roughly symmetric in shape with a center that matches the population mean, and a small SE. The size of the SE reflects the fact that the sample mean tends to be quite close to the population.\n\nAgain, the sampling distribution provides the distribution for the possible values of the sample mean. From this distribution, we find that the chance the sample mean is over 88 is about 0.33, and the chance the sample mean is between 85 and 95 is roughly, 1. \n\n#### Putting the Three Panels Together\n\nLet's look at these three aspects of this process side-by-side.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npop_dist + emp_dist + sampling_dist\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-8-1.png){width=864}\n:::\n:::\n\n\n|             | Population | Empirical   | Sampling\n| ----------- | ----------- | ----------- | ----------- |\n| Shape | left skew | left skew | bell-shaped / normal | \n| Mean | 87.6      | 86.27  | 87.6      | \n| SD | 8.9      | 9.9  | 0.89      | \n\nObserve that:\n\n1. The population mean and the expected sample mean are roughly the same.\n2. The SD of the population and the SE of the sample averages are related in the following way[^finite]:\n\n$$SE(sample~mean) \\approx SD(pop)/\\sqrt{n}$$\n\n3. The histogram of the sample averages is not skewed like the histogram of the box, on the contrary, it is symmetric about the middle and bell-shaped, like the normal curve.\n\n4. The histogram of our sample of 100 resembles the population histogram. \n\n5. Since 100 is a pretty large sample,\n\n$$\n\\begin{aligned}\nmean(pop) &\\approx mean(sample) \\\\\nSD(pop) &\\approx SD(sample) \\\\\n\\end{aligned}\n$$\n\n[^finite]: This approximation becomes equality for a random sample *with replacement*. When we have a SRS, the exact formula is $SE(sample~mean) = \\sqrt{\\frac{N-n}{N-1}} SD(pop)/\\sqrt{n}$.\n\n    This additional term, called the *finite population correction factor*, adjusts for the fact that we are drawing without replacement. Here $N$ is the number of tickets in the box (the size of the population) and $n$ is the number of tickets drawn from the box (the size of the sample).\n\n    To help make sense of this correction factor, think about the following two cases:\n\n    - Draw $N$ tickets from the box (that is, $n = N$).\n    - Draw only one ticket from the box.\n\n    What happens to the SE in these two extreme cases?\n\n    In the first case, you will always see the entire population if you are drawing without replacement. So, the sample mean will exactly match the population mean. The sampling distribution has no variation, so $SE = 0$.\n\n    In the second case, since you take only one draw from the box, it doesn't matter if you replace it or not. So the SE for a SRS should match the SE when sampling with replacement in this special case. In settings when $N$ is large relative to $n$, it effectively behaves as if you are sampling with replacement.\n\n\nNow we're ready to make inferences in a setting where we *don't* know the population.\n\n## Inference for a Population Average\n\nDrawing on our understanding of the thought-experiment, we ask: \n\n*What happens when you don't see the population, you just have your sample, and you want to make an inference about the population?*\n\nWe have serious gaps in our procedure for learning about the sampling distribution!\n\n![](images/triptych-sample-only.jpg){fig-align=center width=400}\n\nTo start, we know we can use the sample average to infer the population average. This is called a *point estimate* for the population parameter. \n\nBut can we do better than that? Can we bring in more of the information that we have learned from the thought-experiment?\nFor example, can we accompany our point estimate with a sense of its accuracy? Ideally, this would be the SE of the sample mean. Unfortunately, we don't know the SE because it depends on the population SD. So now what do we do?\n\n### Standard Error\n\nThe thought-experiment tells us that the sample SD is close to the population SD (when you have a SRS). So we can substitute the sample SD into the formula for the SE.\n\n$$ SE(sample~mean) \\approx \\frac{SD(sample)}{\\sqrt{n}}$$\n\nWhen presenting our findings, you might say, that based on a SRS of 100 restaurants in San Francisco, the average food safety score is estimated to be 86 with a standard error of about\n1.\n\nSuppose someone took a sample of 25 restaurants and provided an estimate of the average food safety score. Is that only 1/4 as accurate because the sample is 1/4 the size of ours?\n\nSuppose someone took a sample of 100 restaurants in New York City where there are 50,000 restaurants (this is a made up number). Is their estimate only 1/10 a accurate because the number of units in the population is 10 times yours?\n\nWe can use the formula for the SE to answer these questions. In the table below, we have calculated these SEs for a generic value of $SD(pop)$ and various choices of the population size and sample size.\n\n| Population Size |  | Sample Size|  | \n| --- | --- | --- | --- |\n|  | 25 | 100 | 400 |\n| 500        | $SE = SD(pop)/5$ | $SE = SD(pop)/10$ | $SE = SD(pop)/20$ |\n| 5,000      | $SE = SD(pop)/5$ | $SE = SD(pop)/10$ | $SE = SD(pop)/20$ | \n| 50,000     | $SE = SD(pop)/5$ | $SE = SD(pop)/ 10$ | $SE = SD(pop)/ 20$ | \n\n\nWhat do you notice about the relationship between sample size and population size and SE?\n\n- The absolute size of the population doesn't enter into the accuracy of the estimate, as long as the sample size is small relative to the population.\n- A sample of 400 is twice as accurate as a sample of 100, which in turn is twice as accurate as a sample of 25 (assuming the population is relatively much larger than the sample). The accuracy improves according to the square root of the sample size. \n\n\n### Confidence Intervals\n\nConfidence intervals bring in more information from the thought-experiment.\nThe confidence interval provides an interval estimate, instead of a point estimate, that is based on spread of the sampling distribution of the statistic.\n\nWe have seen that the sampling distribution is takes a familiar shape: that of the normal curve (also called the bell curve)[^normalassump]. Therefore we can fill in some of the holes in the thought-experiment with approximations.\n\n[^normalassump]: This is not always the case. We'll come back to this point later. \n\n![](images/triptych-subs.jpg){fig-align=center width=400} \n\nThe sketch that we have added in the middle panel shows a sampling distribution that looks like the bell curve. To understand how this will be helpful, let's make a quick\ndigression to talk about the normal distribution.\n\n#### The Normal Distribution\n\nThe normal distribution describes a continuous random variable that has a density function with a familiar bell shape[^normalpdf]. \n\n[^normalpdf]: For a normally distributed random variable, $f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}$. Read more on Wikipedia: <https://en.wikipedia.org/wiki/Normal_distribution>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata.frame(x = seq(-3, 3, .01)) %>%\n  mutate(y = dnorm(x)) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_line() +\n  labs(x = \"x\",\n       y = \"f(x)\") +\n  scale_y_continuous(breaks = NULL) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=384}\n:::\n:::\n\n\nIf a random variable $X$ follows a normal distribution, we write\n\n$$X \\sim \\textrm{N}(\\mu, \\sigma)$$\n\nwhere $\\mu$ is the mean of the distribution and $\\sigma$ is its standard deviation. The particular normal distribution shown above is the *standard normal distribution*, where $\\mu = 0$ and $\\sigma = 1)$.\n\nWe can calculate the probability of any event related to $X$ by finding the area under the curve corresponding to that event. That includes the probability that $X$ falls within a particular interval. In the table below, we record the probabilities of three such intervals.\n\n| Interval | Area under the normal curve |\n| ---- | ---- |\n| Between -1 and 1 | 0.68 |\n| Between -1.96 and 1.96 | 0.95 |\n| Between -2.58 and 2.58 | 0.99 |\n\nSo *if* we know a particular distribution is similar in shape to the normal distribution, we're able to calculate the probabilities that the random variable falls within a particular interval. With this observation in hand, let's return to the task of making an interval estimate.\n\n#### Normal Confidence Intervals\n\nWhen the sampling distribution is roughly normal in shape, then we can construct an interval that expresses exactly how much sampling variability there is. Using our single sample of data and the properties of the normal distribution, we can be 95% confident that the population parameter is within the following interval.\n\n$$[\\bar{x} - 1.96 SE, \\bar{x} + 1.96SE]$$\n\n<!-- So for a sample where the sample mean is `r `round(mean(samp_scores))`, the 95% confidence interval is:  -->\n<!-- [84.3, -->\n<!-- 88.2 ] -->\n<!-- and you would say,  -->\n\n<!-- I am 95% confident that the population mean is between 84.3 and  -->\n<!-- 88.2. -->\n\nWe call this a confidence interval because 95% of the time, an interval constructed in this way will contain the population mean. \nFor the particular interval that you have created, you don't know if it contains the population mean or not. This is why we use the term *confidence* to describe it instead of probability. Probability comes into play when taking the sample, after that our confidence interval is a known observed value with nothing left to chance.\n\n##### Confidence not Probability\n\nTo be more precise about what is meant by \"confidence\", let's take 100 samples of size 25 from the restaurant scores, and calculate a 95% confidence interval for each of our 100 samples. How many of these 100 confidence intervals do you think will include the population mean? \n\nLet's simulate it!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(10312022)\nsamp25_means <- replicate(100, mean(sample(fs_scores, 25)))\n\nlower <- samp25_means - 1.96 * sd(fs_scores)/5\nupper <- samp25_means + 1.96 * sd(fs_scores)/5\ntrial <- 1:100\ncover <- (mean(fs_scores) >= lower) & (mean(fs_scores) <= upper)\nCIs <- data.frame(trial, lower, upper, cover)\n\nci100 <- ggplot(CIs, aes(y = trial)) +\n  geom_segment(aes(x=lower, y=trial, xend=upper, yend=trial, color= cover), \n               show.legend=FALSE) +\n  annotate(\"segment\", x=mean(fs_scores), xend=mean(fs_scores),\n                y=0, yend=101, color=\"black\") +\n  labs(x=expression(bar(x)), y = \"Iteration\") +\n  theme_minimal()\n\nci100\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=480}\n:::\n:::\n\n\nWe have found that 95 of the 100 confidence intervals cover the population parameter. This is by design. If we simulate another 100 times, we may get a different number, but it is likely to be close to 95.\n\n## Inference for a Population Proportion\n\nTo gain practice with making confidence intervals, we turn to another example. This time we sample from a populations where the values are 0s and 1s (0-1 box). You will see that the process is very much the same, although there are a few simplifications that arise due to the nature of the box.\n\n\n::: {.cell}\n\n:::\n\n\nSuppose we only want to eat at restaurants with food safety scores above 95. Let's make a confidence interval for the proportion of restaurants in San Francisco with scores that are \"excellent\" (scores over 95). \nTo tackle this problem, we can modify our box. Since we need only to keep track of whether a score is excellent, we can replace the scores on the tickets with 0s and 1s, where 1 indicates an excellent score. Of the 5766 \nrestaurants in San Francisco, 1240 are excellent. So our box has 5766 tickets in it, and 1240 are marked 1, and 4526 are marked 0. This time let's take a SRS of 25.\n\nThe thought-experiment appears as \n\n\n::: {.cell}\n\n```{.r .cell-code}\nhi_score_dist <- ggplot(as.data.frame(hi_scores), \n                        aes(x=hi_scores, y=..density..)) + \n      geom_histogram(breaks=seq(-0.5, 1.5, by = 1), \n                 color=\"black\", fill=\"gray\") + \n      xlab(\"Excellent score?\") +\n      ylab(\"Proportion\") +\n      ggtitle(\"Population\")\n\nhi_samp_dist <- ggplot(as.data.frame(hi_score_samp), aes(x=hi_score_samp, y=..density..)) + \n      geom_histogram(breaks=seq(-0.5, 1.5, by = 1), \n                 color=\"black\", fill=\"gray\") + \n      xlab(\"Excellent scores?\") +\n      ylab(\"Proportion\") +\n      ggtitle(\"Empirical Distribution\")\n\nhi_sampling_dist <- ggplot(as.data.frame(hi_score_means), \n                        aes(x=hi_score_means, y=..density..)) + \n      geom_histogram(bins = 20, \n                 color=\"black\", fill=\"gray\") + \n      xlab(\"Proportion excellent\") +\n      ylab(\"Proportion\") +\n      ggtitle(\"Sampling Distribution\")\n\nhi_score_dist + hi_samp_dist + hi_sampling_dist\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-12-1.png){width=864}\n:::\n:::\n\n\n\n|             | Population  | Empirical   | Sampling | \n| ----------- | ----------- | ----------- | ----------- |\n| Shape | left skew | left skew | bell-shaped / normal |\n| Mean | 0.22      |  0.2  | 0.22      |\n| SD | 0.4      | 0.4  | 0.08      |\n\nIn the special case of a 0-1 box:\n\n+ The population average is the proportion of 1s in the box, let's call this parameter $p$. \n+ The taking a draw from the population distribution taking a draw from a Bernoulli random variable, so $SD(pop) = \\sqrt{p(1-p)}$.\n+ The sampling distribution has mean $p$.\n+ The sampling proportion, $\\hat{p}$, is similar to $p$.\n+ The SE of the sample proportion[^sdp] is approximately $SE(\\hat{p}) = \\frac{\\sqrt{\\hat{p}(1-\\hat{p})}}{\\sqrt{n}}$.\n\nWith an equation to estimate $SE$ from our data in hand, we can form a 95% confidence interval.\n\n$$\\left[\\hat{p} - 1.96 \\frac{\\sqrt{\\hat{p}(1-\\hat{p})}}{\\sqrt{n}}, \\hat{p} + 1.96 \\frac{\\sqrt{\\hat{p}(1-\\hat{p})}}{\\sqrt{n}}\\right]$$\n\n[^sdp]: This calculation results from casting the total number of 1's in a sample of size $n$ as a binomial random variable with success probability $p$. Call that random variable $Y$. The variance of a binomial random variable is $Var(Y) = np(1-p)$. Observing that sample proportion can be considered a binomial count divided by $n$, and applying the properties of variance, we can find the variance of $\\hat{p}$ as,\n\n    \\begin{eqnarray}\n    Var(\\hat{p}) &= Var(\\frac{1}{n}Y) \\\\\n    &= \\frac{1}{n^2}Var(Y) \\\\\n    &= \\frac{1}{n^2}np(1-p) \\\\\n    &= \\frac{p(1-p)}{n}\n    \\end{eqnarray}\n    \n    So the standard error can be calculated as:\n    \n    \\begin{eqnarray}\n    SE(\\hat{p}) &= \\sqrt{Var(\\hat{p})} = \\sqrt{\\frac{p(1-p)}{n}}\n    \\end{eqnarray}\n    \n    When estimating the SE from data, we plug in $\\hat{p}$ for $p$.\n\n<!-- Let's make a 99% confidence interval for the proportion of restaurants with scores at least 95,  -->\n<!-- [0.09, 0.31 ]. -->\n\n## Summary\n\nIn these notes, we have restricted ourselves to the simple random sample, where the only source of error that we're concerned with is sampling variability. We outlined two tools for estimating that variability: the standard error (SE) and the confidence interval.\n\nWe saw how the size of the sample impacts the standard error of the estimate. The larger the sample, the more accurate our estimates are and in particular the accuracy improves according to $1/\\sqrt{n}$. We also found that the size of the population doesn't impact the accuracy, as long as the sample is small compared to the population.   \n\nWe made confidence intervals for population averages and proportions using the normal distribution. This approach can be extended to other properties of a population, such as the median of a population, or the coefficient in a regression equation.\n\nThe confidence intervals that we have made are approximate in the following sense:\n\n+ We're approximating the shape of the unknown sampling distribution with the normal curve.\n+ The SD of the sample is used in place of the SD of the population in  calculating the SE of the statistic.\n\nThere are times when we are unwilling to make the assumption of normality. This is the topic of the next set of notes. \n\n\n## Materials from class\n\n#### Slides\n\n- [Andrew](slides.qmd)\n- [Silas](slides.qmd)\n- [Shobhana](slides.qmd)\n- [Jeremy](slides.qmd)\n\n\n\n:::{.content-hidden unless-profile=\"staff-guide\"}\n## Learning Objectives\n\n#### Concept Acquisition\n\n#### Tool Acquisition\n\n#### Concept Application\n\n#### Key Terms\n\n:::\n\n<!-- [I]{.dropcap}n the last set of notes, we used a thought experiment to understand the ways in which the professor calling on students from the front row could yield estimates that are in error. In this thought experiment, we had access to the population, the set of all 527 students in the class, whose distribution is shown in the top row of the plot below. The population parameter that the professor sought to learn was the mean year of those 527 students, 1.72, indicated by a gold triangle. -->\n\n<!-- To estimate that parameter, on the first day of class the professor called on a sample of the 18 students sitting in the front row. The empirical distribution of the years of those 18 students is shown below as Sample 1. Because first year students are more eager and thus more likely to sit in the front row, it is not surprising that they were over-represented in this distribution. As a consequence, the sample mean, 1.44 (shown as a blue triangle), underestimates the population mean. -->\n\n<!-- That selection bias, however, isn't the only source of error. Every day in class, there is some degree of randomness in which seats students sit in, so the group of students in the front row varies. Imagine on the second day, with the students in a slightly different seating configuration, the professor calls on the front row again. A different set of 18 students respond with their years; their empirical distribution shown in Sample 2. -->\n\n<!-- The sample on day two is different from the sample on day one, so the sample mean is a bit different too: 1.39. You can imagine repeating this thought experiment on day three, and on day four, and on day five . . . each time collecting a new slightly different sample of 18 students with their own slightly different sample mean. The distribution of those sample means is the sampling distribution. -->\n\n<!-- ```{r} -->\n<!-- library(tidyverse) -->\n<!-- pop_eager <- data.frame(year = rep(c(1, 2, 3, 4),  -->\n<!--                                    times = c(245, 210, 47, 25)), -->\n<!--                         eagerness = rep(c(10, 6, 3, 1),  -->\n<!--                                         times = c(245, 210, 47, 25))) -->\n<!-- set.seed(55) -->\n<!-- pop_eager <- pop_eager %>% -->\n<!--   slice_sample(n = nrow(pop_eager))  -->\n\n<!-- mu <- mean(pop_eager$year) -->\n\n<!-- p_pop <- pop_eager %>% -->\n<!--   ggplot(aes(x = year)) + -->\n<!--   geom_bar(fill = \"purple\") + -->\n<!--   labs(title = \"Population Distribution\", -->\n<!--        y = \"\") + -->\n<!--   annotate(\"point\", x = mu, y = -20, shape = 17, size = 5, color = \"goldenrod2\") + -->\n<!--   theme_gray(base_size = 10) + -->\n<!--   theme(plot.title = element_text(size=10)) -->\n\n<!-- library(infer) -->\n<!-- samp_1 <- pop_eager %>% -->\n<!--   slice_sample(n = 18, -->\n<!--                    replace = FALSE, -->\n<!--                    weight_by = eagerness)  -->\n\n<!-- many_samps <- samp_1 %>% -->\n<!--   mutate(Sample = 1) -->\n\n<!-- for (i in 2:500) { -->\n<!--   many_samps <- pop_eager %>% -->\n<!--     slice_sample(n = 18, -->\n<!--                  replace = FALSE, -->\n<!--                  weight_by = eagerness) %>% -->\n<!--     mutate(Sample = i ) %>% -->\n<!--     bind_rows(many_samps) -->\n<!-- } -->\n\n<!-- xbar1 <- many_samps %>% -->\n<!--   filter(Sample == 1) %>% -->\n<!--   summarize(mean(year)) %>% -->\n<!--   pull() -->\n\n<!-- xbar2 <- many_samps %>% -->\n<!--   filter(Sample == 2) %>% -->\n<!--   summarize(mean(year)) %>% -->\n<!--   pull() -->\n\n<!-- xbar3 <- many_samps %>% -->\n<!--   filter(Sample == 3) %>% -->\n<!--   summarize(mean(year)) %>% -->\n<!--   pull() -->\n\n<!-- p1 <- many_samps %>% -->\n<!--   filter(Sample == 1) %>% -->\n<!--   ggplot(aes(x = year)) +  -->\n<!--   geom_bar() + -->\n<!--   labs(title = \"Sample 1\", -->\n<!--        y = \"\") + -->\n<!--   annotate(\"point\", x = xbar1, y = 0, shape = 17,  -->\n<!--            size = 4, color = \"steelblue\") + -->\n<!--   theme_gray(base_size = 10) + -->\n<!--   theme(plot.title = element_text(size=10)) -->\n\n<!-- p2 <- many_samps %>% -->\n<!--   filter(Sample == 2) %>% -->\n<!--   ggplot(aes(x = year)) +  -->\n<!--   geom_bar() + -->\n<!--   labs(title = \"Sample 2\", -->\n<!--        y = \"\") + -->\n<!--   annotate(\"point\", x = xbar2, y = 0, shape = 17,  -->\n<!--            size = 4, color = \"steelblue\") + -->\n<!--   theme_gray(base_size = 10) + -->\n<!--   theme(plot.title = element_text(size=10)) -->\n\n<!-- p3 <- many_samps %>% -->\n<!--   filter(Sample == 3) %>% -->\n<!--   ggplot(aes(x = year)) +  -->\n<!--   geom_bar() + -->\n<!--   labs(title = \"Sample 3\", -->\n<!--        y = \"\") + -->\n<!--   annotate(\"point\", x = xbar3, y = 0, shape = 17,  -->\n<!--            size = 4, color = \"steelblue\") + -->\n<!--   theme_gray(base_size = 10) + -->\n<!--   theme(plot.title = element_text(size=10)) -->\n\n<!-- # fix limits -->\n<!-- xlims_from_samps <- list(ggplot_build(p1)$layout$panel_scales_x[[1]]$range$range, -->\n<!--            ggplot_build(p2)$layout$panel_scales_x[[1]]$range$range, -->\n<!--            ggplot_build(p3)$layout$panel_scales_x[[1]]$range$range) -->\n<!-- max_xlims <- unlist(xlims_from_samps[which.max(lapply(xlims_from_samps, diff))]) -->\n\n<!-- ylims_from_samps <- list(ggplot_build(p1)$layout$panel_scales_y[[1]]$range$range, -->\n<!--            ggplot_build(p2)$layout$panel_scales_y[[1]]$range$range, -->\n<!--            ggplot_build(p3)$layout$panel_scales_y[[1]]$range$range) -->\n<!-- max_ylims <- unlist(ylims_from_samps[which.max(lapply(ylims_from_samps, diff))]) -->\n\n<!-- p1 <- p1 + -->\n<!--   lims(x = max_xlims, -->\n<!--        y = max_ylims) -->\n\n<!-- p2 <- p2 + -->\n<!--   lims(x = max_xlims, -->\n<!--        y = max_ylims) -->\n\n<!-- p3 <- p3 + -->\n<!--   lims(x = max_xlims, -->\n<!--        y = max_ylims) -->\n\n<!-- sample_labels <- c(\"1\" = \"Sample 1\", -->\n<!--                    \"2\" = \"Sample 2\", -->\n<!--                    \"3\" = \"Sample 3\") -->\n\n<!-- p_samps <- many_samps %>% -->\n<!--   filter(Sample %in% 1:3) %>% -->\n<!--   ggplot(aes(x = year)) +  -->\n<!--   geom_bar() + -->\n<!--   labs(y = \"\") + -->\n<!--   facet_wrap(vars(Sample), -->\n<!--              labeller = labeller(Sample = sample_labels)) + -->\n<!--   theme_gray(base_size = 10) -->\n\n<!-- many_xbars <- many_samps %>% -->\n<!--   group_by(Sample) %>% -->\n<!--   summarize(xbar = mean(as.numeric(year))) -->\n\n<!-- xlims_from_pop <- ggplot_build(p_pop)$layout$panel_scales_x[[1]]$range$range -->\n\n<!-- p_samp_dist <- many_xbars %>% -->\n<!--   ggplot(aes(x = xbar)) + -->\n<!--   geom_bar(fill = \"steelblue\") + -->\n<!--   lims(x = c(0, 4)) + -->\n<!--   labs(title = \"Sampling Distribution\", -->\n<!--        y = \"\", -->\n<!--        x = expression(paste(bar(x), \" (mean year)\"))) + -->\n<!--   annotate(\"point\", x = mu, y = -10, shape = 17, size = 5, color = \"goldenrod2\") + -->\n<!--   theme_gray(base_size = 10) + -->\n<!--   theme(plot.title = element_text(size=10)) + -->\n<!--   lims(x = xlims_from_pop) -->\n\n<!-- library(patchwork) -->\n\n<!-- triptych <- (plot_spacer() + p_pop + plot_spacer()) /  -->\n<!--   (p1 + p2 + p3) /  -->\n<!--   (plot_spacer() + p_samp_dist + plot_spacer()) -->\n<!-- triptych -->\n<!-- ``` -->\n\n<!-- This sampling distribution contains 500 sample means. The selection bias in calling only on the front row -->\n",
    "supporting": [
      "notes_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}